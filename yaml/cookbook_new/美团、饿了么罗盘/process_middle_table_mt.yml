cookbook: true
mt_daily_env:
  context_defaults:
    delay_compute: true
    sync_result_from_cluster: true
    play_on_dask_cluster: true
    platform_code: meituan
    dask_client_set_as_default: true
    cluster_client_address: 'dask-scheduler-service.databus:8786'

  play:
    - name: mt_dc_cum_month    #月累计站点数据
      sync_result: true
      cooks:
        - fetch_dataset:
            template_code: mt_day_35        #日累计站点数据
            dataset_cate: raw
            datakit_pull_way: last_day
            columns: [ 站点id,注册骑手数,离职骑手数,入职骑手数,有完成单骑手数,完成单量,人效（完成订单）,meta_day ]
            ignore_null_error: true
            empty_df_record:
              站点id: '-'
              注册骑手数: 1
              离职骑手数: 1
              入职骑手数: 1
              有完成单骑手数: 1
              完成单量: 1
              meta_day: 99999999
              人效（完成订单）: 0.0
            rename:
              站点id: vendor_dc_id
              注册骑手数: register_knight #register_knight
              离职骑手数: total_leave_knight #leave_knight
              入职骑手数: total_entry_knight #entry_knight
              有完成单骑手数: total_have_order_knight #have_order_knight
              完成单量: total_order  #single_daily_order
              人效（完成订单）: total_utility
        - df_to_int:
            - register_knight
        - df_to_int:
            - total_leave_knight
        - df_to_int:
            - total_entry_knight
        - df_to_int:
            - total_have_order_knight
        - df_to_int:
            - total_order
        - df_to_float:
            - total_utility
        - df_eval:
            - |
              [total_register_knight] = [register_knight] + [total_leave_knight]
        - fetch_cols:
            columns: [vendor_dc_id,meta_day,total_register_knight,total_leave_knight,total_entry_knight,total_order,total_utility]
        - stash_push_df: []
        - fetch_dataset:
            template_code: mt_day_61        #单日站点数据
            dataset_cate: raw
            columns: [ 站点id,有完成单骑手数,meta_day ]
            ignore_null_error: true
            empty_df_record:
              站点id: '-'
              有完成单骑手数: 1
              meta_day: 99999999
            rename:
              站点id: vendor_dc_id
              有完成单骑手数: have_order_knight
        - df_to_int:
            - have_order_knight
        - run_py:
            - |
              df = to_df(df)
              need = df.groupby(by=['vendor_dc_id']).apply(lambda x: x.sort_values(by=['meta_day'])).reset_index(drop=True)
              need_result = need.groupby(by=['vendor_dc_id']).cumsum().rename(columns={'have_order_knight':'total_have_order_knight','meta_day':'meta_day_other'})
              need = pd.merge(need,need_result,left_index=True,right_index=True,how='inner')
              need_days = need.groupby(by=['vendor_dc_id'])['meta_day'].count().reset_index().rename(columns={'meta_day':'days'})
              need = pd.merge(need,need_days,how ='inner',on=['vendor_dc_id'])
              need['avg_daily_knight'] = need['total_have_order_knight'] / need['days']
              result = to_dd(need)
        - fetch_cols:
            columns: [vendor_dc_id,meta_day,avg_daily_knight]
        - stash_push_df: []
        - stash_join_df:
            on: [vendor_dc_id,meta_day]
            how: outer
            drop_stash: true
        - fetch_cols:
            columns: [vendor_dc_id,meta_day,total_register_knight,total_leave_knight,total_entry_knight,total_order,total_utility,avg_daily_knight]


    - name: mt_total_details_dc_median
      sync_result: true
      cooks:
        - fetch_dataset:
            template_code: mt_day_61        #单日站点数据
            dataset_cate: raw
            columns: [站点名称,站点id,注册骑手数,离职骑手数,入职骑手数,有完成单骑手数,完成单量,人效（完成订单）,加盟商ID,meta_day]
            ignore_null_error: true
            empty_df_record:
              站点名称: '-'
              站点id: '-'
              注册骑手数: 1
              离职骑手数: 1
              入职骑手数: 1
              有完成单骑手数: 1
              完成单量: 1
              人效（完成订单）: 1.0
              加盟商ID: '-'
              meta_day: 99999999
            rename:
              站点名称: dc_name
              站点id: vendor_dc_id
              注册骑手数: register_knight_zc
              离职骑手数: leave_knight
              入职骑手数: entry_knight
              有完成单骑手数: have_order_knight
              完成单量: single_daily_order
              人效（完成订单）: single_utility
              加盟商ID: alliance_id
        - df_to_int:
            - register_knight_zc
        - df_to_int:
            - leave_knight
        - df_to_int:
            - entry_knight
        - df_to_int:
            - have_order_knight
        - df_to_int:
            - single_daily_order
        - df_to_float:
            - single_utility
        - fetch_cols:
            columns: [dc_name,vendor_dc_id,register_knight_zc,leave_knight,entry_knight,have_order_knight,single_daily_order,single_utility,alliance_id,meta_day]
        - stash_push_df: []

        - use_df:
            key: mt_dc_cum_month

        - stash_push_df: []
        - stash_join_df:
            on: [vendor_dc_id,meta_day]
            how: outer
            drop_stash: true
        - df_to_int:
            - total_leave_knight
        - df_eval:
            - |
              [register_knight] = [register_knight_zc] + [total_leave_knight]
        - stash_push_df: []
        - fetch_dataset:
            template_code: mt_day_13    # 日星级结果
            dataset_cate: raw
            columns: [加盟站ID,加盟站名称,得分,星级,完成单(未剔除异常单),meta_day]
            ignore_null_error: true
            empty_df_record:
              加盟站名称: '-'
              加盟站ID: '-'
              得分: 0.0
              星级: 0.0
              完成单(未剔除异常单): 0
              meta_day: 99999999
            rename:
              加盟站名称: dc_name
              加盟站ID: vendor_dc_id
              得分: kpi_score
              星级: star_level
              完成单(未剔除异常单): over_order_no_sub
        - df_to_int:
            - over_order_no_sub
        - df_to_float:
            - kpi_score
        - df_to_float:
            - star_level
        - stash_push_df: []
        - stash_join_df:
            on: [vendor_dc_id,dc_name,meta_day]
            how: outer
            drop_stash: true
        - df_to_float:
            - have_order_knight
        - df_to_float:
            - register_knight
        - df_to_float:
            - entry_knight
        - df_to_float:
            - leave_knight
        - df_to_float:
            - total_entry_knight
        - df_to_float:
            - total_register_knight
        - df_to_float:
            - total_leave_knight

        - run_py:
            - |
              df['have_order_ratio'] = df['have_order_knight'] / df['register_knight']
              df['entry_ratio'] = df['entry_knight'] / df['register_knight']
              df['leave_ratio'] = df['leave_knight'] / df['register_knight']
              df['total_entry_ratio'] = df['total_entry_knight'] /  df['total_register_knight']
              df['total_leave_ratio'] = df['total_leave_knight'] / df['total_register_knight']
              result = df
        - fetch_cols:
            columns: [meta_day,vendor_dc_id,dc_name,over_order_no_sub,kpi_score,star_level,avg_daily_knight,total_order,total_leave_knight,total_entry_knight,total_register_knight,total_utility,leave_knight,have_order_knight,alliance_id,single_utility,single_daily_order,entry_knight,register_knight_zc,register_knight,have_order_ratio,entry_ratio,leave_ratio,total_entry_ratio,total_leave_ratio]
        - stash_push_df: []

        - fetch_dataset:
            template_code: mt_day_59     # AA站点难度等级明细
            dataset_cate: raw
            columns: [站点ID,难度等级]
            ignore_null_error: true
            empty_df_record:
              站点ID: '-'
              难度等级: '-'
            rename:
              站点ID: vendor_dc_id
              难度等级: difficulty_level
        - stash_push_df:  []
        - stash_join_df:
            on: [vendor_dc_id]
            how: outer
            drop_stash: true

        - run_py:
            - |
              df = to_df(df)
              df_days = df.groupby(by=['vendor_dc_id'])['meta_day'].count().reset_index().rename(columns={'meta_day':'days'})
              df = pd.merge(df,df_days,how ='inner',on=['vendor_dc_id'])
              result = to_dd(df)
#              df['days'] = df['meta_day'].map(str).str[6:].map(int)
        - df_to_int:
            - total_order
        - df_eval:
            - |
              [avg_daily_order] = [total_order] / [days]
        - stash_push_df: []

        - fetch_dataset:
            dataset_type_code: std_qplus_dc
            dataset_cate: std
            columns: [platform_code,supplier_id,supplier_name,city_name,vendor_dc_id]
            ignore_null_error: true
        - when_empty_fetch_dataset:
            dataset_type_code: std_qplus_dc
            dataset_cate: std
            columns: [platform_code,supplier_id,supplier_name,city_name,vendor_dc_id]
            month_offset: -1
            ignore_null_error: true
        - drop_duplicates:
            subset: [ platform_code,supplier_id,vendor_dc_id  ]
        - df_select:
            - '[platform_code] == @p1'
            - p1: meituan
        - stash_push_df: []
        - stash_join_df:
            on: [vendor_dc_id]
            how: inner
            drop_stash: true
        - add_cols:
            - dc_count: 1
              dimension: 'D'
        - push_dataset:
            key: mt_total_details_dc_mini

        - df_select:
            - '[supplier_id] in @p1'
            - p1: ['5b9738f4ce6d2abdaed16a8e','5b9738f5ce6d2abdaed16e09']
        ### 总参与排名商圈数、 全量单排名、日单量排名、日均单排名、 日均骑手量排名、当日人效排名、累计人效排名、KPI得分排名、星级排名、日留存排名
        - run_py:
            - |
              df = to_df(df)
              total_rank_count = df[["total_order","single_daily_order","avg_daily_order","avg_daily_knight","single_utility","total_utility","meta_day"]].groupby(by=['meta_day']).count().reset_index().rename(columns={"total_order":"total_order_join_rank_count","single_daily_order":"single_daily_order_join_rank_count","avg_daily_order":"avg_daily_order_join_rank_count","avg_daily_knight":"avg_daily_knight_join_rank_count","single_utility":"single_utility_join_rank_count","total_utility":"total_utility_join_rank_count"})
              df = pd.merge(df,total_rank_count,on=['meta_day'],how='left',sort=False)
              df['total_order_rank'] = df.groupby(by=['meta_day'])['total_order'].rank(method='min',ascending=False)
              df['single_daily_order_rank'] = df.groupby(by=['meta_day'])['single_daily_order'].rank(method='min',ascending=False)
              df['avg_daily_order_rank'] = df.groupby(by=['meta_day'])['avg_daily_order'].rank(method='min',ascending=False)
              df['avg_daily_knight_rank'] = df.groupby(by=['meta_day'])['avg_daily_knight'].rank(method='min',ascending=False)
              df['single_utility_rank'] = df.groupby(by=['meta_day'])['single_utility'].rank(method='min',ascending=False)
              df['total_utility_rank'] = df.groupby(by=['meta_day'])['total_utility'].rank(method='min',ascending=False)
              df['kpi_score_rank'] = df.groupby(by=['meta_day'])['kpi_score'].rank(method='min',ascending=False)
              df['star_level_rank'] = df.groupby(by=['meta_day'])['star_level'].rank(method='min',ascending=False)
              df['daily_stay_ratio'] = 1 - df['total_leave_ratio']
              df['daily_stay_ratio_rank'] = df.groupby(by=['meta_day'])['daily_stay_ratio'].rank(method='min',ascending=False)
              result =  to_dd(df)
        - push_dataset:
            key: mt_total_details_dc_mini_yjd_and_rd
        - stash_push_df: []

        - use_df:
            key: mt_total_details_dc_mini
        - df_select:
            - '[supplier_id] == @p1'
            - p1: '5c8f38ae887d1f1c43bfc06e'
        ### 总参与排名商圈数、 全量单排名、日单量排名、日均单排名、 日均骑手量排名、当日人效排名、累计人效排名、KPI得分排名、星级排名、日留存排名
        - run_py:
            - |
              df = to_df(df)
              total_rank_count = df[["total_order","single_daily_order","avg_daily_order","avg_daily_knight","single_utility","total_utility","meta_day"]].groupby(by=['meta_day']).count().reset_index().rename(columns={"total_order":"total_order_join_rank_count","single_daily_order":"single_daily_order_join_rank_count","avg_daily_order":"avg_daily_order_join_rank_count","avg_daily_knight":"avg_daily_knight_join_rank_count","single_utility":"single_utility_join_rank_count","total_utility":"total_utility_join_rank_count"})
              df = pd.merge(df,total_rank_count,on=['meta_day'],how='left',sort=False)
              df['total_order_rank'] = df.groupby(by=['meta_day'])['total_order'].rank(method='min',ascending=False)
              df['single_daily_order_rank'] = df.groupby(by=['meta_day'])['single_daily_order'].rank(method='min',ascending=False)
              df['avg_daily_order_rank'] = df.groupby(by=['meta_day'])['avg_daily_order'].rank(method='min',ascending=False)
              df['avg_daily_knight_rank'] = df.groupby(by=['meta_day'])['avg_daily_knight'].rank(method='min',ascending=False)
              df['single_utility_rank'] = df.groupby(by=['meta_day'])['single_utility'].rank(method='min',ascending=False)
              df['total_utility_rank'] = df.groupby(by=['meta_day'])['total_utility'].rank(method='min',ascending=False)
              df['kpi_score_rank'] = df.groupby(by=['meta_day'])['kpi_score'].rank(method='min',ascending=False)
              df['star_level_rank'] = df.groupby(by=['meta_day'])['star_level'].rank(method='min',ascending=False)
              df['daily_stay_ratio'] = 1 - df['total_leave_ratio']
              df['daily_stay_ratio_rank'] = df.groupby(by=['meta_day'])['daily_stay_ratio'].rank(method='min',ascending=False)
              result =  to_dd(df)
        - push_dataset:
            key: mt_total_details_dc_mini_xd
        - stash_push_df: []
        - stash_concat_df:
            drop_stash: true

    - name: mt_total_details_dc
      sync_result: true
      cooks:
        - use_df:
            key: mt_total_details_dc_median
            columns: [supplier_id,vendor_dc_id,meta_day,total_order_rank,single_daily_order_rank,avg_daily_order,avg_daily_order_rank,avg_daily_knight,avg_daily_knight_rank,single_utility,single_utility_rank,total_utility,total_utility_rank]
        - df_rename_columns:
            - total_order_rank: total_order_rank_before
              single_daily_order_rank: single_daily_order_rank_before
              avg_daily_order: avg_daily_order_before
              avg_daily_order_rank: avg_daily_order_rank_before
              avg_daily_knight: avg_daily_knight_before
              avg_daily_knight_rank: avg_daily_knight_rank_before
              single_utility: single_utility_before
              single_utility_rank: single_utility_rank_before
              total_utility: total_utility_before
              total_utility_rank: total_utility_rank_before
        - run_py:
            - |
              df['meta_day'] = df['meta_day'] + 1
              result = df
        - stash_push_df: []

        - use_df:
            key: mt_total_details_dc_median
        - stash_push_df: []
        - stash_join_df:
            on: [supplier_id,vendor_dc_id,meta_day]
            how: left
            drop_stash: true
        ### 全量单排名状态
        - add_cols:
            - total_order_rank_status: '-'
        - df_set_column_val_if:
            column: total_order_rank_status
            condition: '[total_order_rank] > [total_order_rank_before]'
            val: 'down'
        - df_set_column_val_if:
            column: total_order_rank_status
            condition: '[total_order_rank] < [total_order_rank_before]'
            val: 'up'
        - df_set_column_val_if:
            column: total_order_rank_status
            condition: '[total_order_rank] == [total_order_rank_before]'
            val: 'equal'
        ###  日单量排名状态
        - add_cols:
            - single_daily_order_rank_status: '-'
        - df_set_column_val_if:
            column: single_daily_order_rank_status
            condition: '[single_daily_order_rank] > [single_daily_order_rank_before]'
            val: 'down'
        - df_set_column_val_if:
            column: single_daily_order_rank_status
            condition: '[single_daily_order_rank] < [single_daily_order_rank_before]'
            val: 'up'
        - df_set_column_val_if:
            column: single_daily_order_rank_status
            condition: '[single_daily_order_rank] == [single_daily_order_rank_before]'
            val: 'equal'
        ### 日均单排名状态
        - add_cols:
            - avg_daily_order_rank_status: '-'
        - df_set_column_val_if:
            column: avg_daily_order_rank_status
            condition: '[avg_daily_order_rank] > [avg_daily_order_rank_before]'
            val: 'down'
        - df_set_column_val_if:
            column: avg_daily_order_rank_status
            condition: '[avg_daily_order_rank] < [avg_daily_order_rank_before]'
            val: 'up'
        - df_set_column_val_if:
            column: avg_daily_order_rank_status
            condition: '[avg_daily_order_rank] == [avg_daily_order_rank_before]'
            val: 'equal'
        ### 日均骑手量排名状态
        - add_cols:
            - avg_daily_knight_rank_status: '-'
        - df_set_column_val_if:
            column: avg_daily_knight_rank_status
            condition: '[avg_daily_knight_rank] > [avg_daily_knight_rank_before]'
            val: 'down'
        - df_set_column_val_if:
            column: avg_daily_knight_rank_status
            condition: '[avg_daily_knight_rank] < [avg_daily_knight_rank_before]'
            val: 'up'
        - df_set_column_val_if:
            column: avg_daily_knight_rank_status
            condition: '[avg_daily_knight_rank] == [avg_daily_knight_rank_before]'
            val: 'equal'
        ### 当日人效排名状态
        - add_cols:
            - single_utility_rank_status: '-'
        - df_set_column_val_if:
            column: single_utility_rank_status
            condition: '[single_utility_rank] > [single_utility_rank_before]'
            val: 'down'
        - df_set_column_val_if:
            column: single_utility_rank_status
            condition: '[single_utility_rank] < [single_utility_rank_before]'
            val: 'up'
        - df_set_column_val_if:
            column: single_utility_rank_status
            condition: '[single_utility_rank] == [single_utility_rank_before]'
            val: 'equal'
        ### 累计人效排名状态
        - add_cols:
            - total_utility_rank_status: '-'
        - df_set_column_val_if:
            column: total_utility_rank_status
            condition: '[total_utility_rank] > [total_utility_rank_before]'
            val: 'down'
        - df_set_column_val_if:
            column: total_utility_rank_status
            condition: '[total_utility_rank] < [total_utility_rank_before]'
            val: 'up'
        - df_set_column_val_if:
            column: total_utility_rank_status
            condition: '[total_utility_rank] == [total_utility_rank_before]'
            val: 'equal'


        ### 日均单环比增长, 日均骑手量环比增长,当日人效环比增长 ,累计人效环比增长
        - df_eval:
            - |
              [avg_daily_order_year_ratio] = ([avg_daily_order] - [avg_daily_order_before]) / [avg_daily_order_before]
              [avg_daily_knight_year_ratio] = ([avg_daily_knight] - [avg_daily_knight_before]) / [avg_daily_knight_before]
              [single_utility_year_ratio] = ([single_utility] - [single_utility_before]) / [single_utility_before]
              [total_utility_year_ratio] = ([total_utility] - [total_utility_before]) / [total_utility_before]
      ### 日均单环比状态
        - add_cols:
            - avg_daily_order_year_ratio_status: '-'
        - df_set_column_val_if:
            column: avg_daily_order_year_ratio_status
            condition: '[avg_daily_order_year_ratio] > 0'
            val: 'up'
        - df_set_column_val_if:
            column: avg_daily_order_year_ratio_status
            condition: '[avg_daily_order_year_ratio] < 0 '
            val: 'down'
        - df_set_column_val_if:
            column: avg_daily_order_year_ratio_status
            condition: '[avg_daily_order_year_ratio] == 0'
            val: 'equal'
      ### 日均骑手量环比状态
        - add_cols:
            - avg_daily_knight_year_ratio_status: '-'
        - df_set_column_val_if:
            column: avg_daily_knight_year_ratio_status
            condition: '[avg_daily_knight_year_ratio] > 0'
            val: 'up'
        - df_set_column_val_if:
            column: avg_daily_knight_year_ratio_status
            condition: '[avg_daily_knight_year_ratio] < 0 '
            val: 'down'
        - df_set_column_val_if:
            column: avg_daily_knight_year_ratio_status
            condition: '[avg_daily_knight_year_ratio] == 0'
            val: 'equal'
      ### 当日人效环比状态
        - add_cols:
            - single_utility_year_ratio_status: '-'
        - df_set_column_val_if:
            column: single_utility_year_ratio_status
            condition: '[single_utility_year_ratio] > 0'
            val: 'up'
        - df_set_column_val_if:
            column: single_utility_year_ratio_status
            condition: '[single_utility_year_ratio] < 0 '
            val: 'down'
        - df_set_column_val_if:
            column: single_utility_year_ratio_status
            condition: '[single_utility_year_ratio] == 0'
            val: 'equal'
      ###累计人效环比状态
        - add_cols:
            - total_utility_year_ratio_status: '-'
        - df_set_column_val_if:
            column: total_utility_year_ratio_status
            condition: '[total_utility_year_ratio] > 0'
            val: 'up'
        - df_set_column_val_if:
            column: total_utility_year_ratio_status
            condition: '[total_utility_year_ratio] < 0 '
            val: 'down'
        - df_set_column_val_if:
            column: total_utility_year_ratio_status
            condition: '[total_utility_year_ratio] == 0'
            val: 'equal'

        - fetch_cols:
            columns: [supplier_id,supplier_name,city_name,vendor_dc_id,dc_name,alliance_id,meta_day,dimension,total_join_rank_count,dc_count,total_order,single_daily_order,single_daily_order_rank,single_daily_order_rank_status,total_order_rank,total_order_rank_status,avg_daily_order,avg_daily_order_rank,avg_daily_order_rank_status,avg_daily_order_year_ratio,avg_daily_order_year_ratio_status,avg_daily_knight,avg_daily_knight_rank,avg_daily_knight_rank_status,avg_daily_knight_year_ratio,avg_daily_knight_year_ratio_status,single_utility,single_utility_rank,single_utility_rank_status,single_utility_year_ratio,total_utility,total_utility_year_ratio,total_utility_year_ratio_status,total_utility_rank,total_utility_rank_status,single_utility_year_ratio_status,have_order_knight,have_order_ratio,entry_knight,entry_ratio,leave_knight,leave_ratio,kpi_score,star_level,kpi_score_rank,difficulty_level,star_level_rank,daily_stay_ratio_rank,daily_stay_ratio,over_order_no_sub,total_leave_ratio,total_entry_ratio,total_entry_knight,total_leave_knight,total_order_join_rank_count,single_daily_order_join_rank_count,avg_daily_order_join_rank_count,avg_daily_knight_join_rank_count,single_utility_join_rank_count,total_utility_join_rank_count]
        - set_meta_month_column:
            - book_month

    - name: mt_city_cum_month    # 月累计城市数据
      sync_result: true
      cooks:
        - fetch_dataset:
            template_code: mt_day_58       #单日城市数据
            dataset_cate: raw
            columns: [ 加盟商ID,注册骑手数,有完成单骑手数,完成单量,meta_day ]
            ignore_null_error: true
            empty_df_record:
              加盟商ID: '-'
              注册骑手数: 1
              有完成单骑手数: 1
              完成单量: 1
              meta_day: 99999999
            rename:
              加盟商ID: alliance_id
              注册骑手数: total_register_knight_zc
              有完成单骑手数: have_order_knight
              完成单量: single_daily_order
        - drop_duplicates:
            subset: [alliance_id,meta_day]
        - df_to_int:
            - total_register_knight_zc
        - df_to_int:
            - have_order_knight
        - df_to_int:
            - single_daily_order
        - stash_push_df: []
        - use_df:
            key: mt_total_details_dc
            columns: [ supplier_id,city_name,alliance_id ]
        - drop_duplicates:
            subset: [ supplier_id,city_name,alliance_id ]
        - stash_push_df: []
        - stash_join_df:
            on: [alliance_id]
            how: inner
            drop_stash: true
        - df_groupby:
            by: [supplier_id,city_name,meta_day]
        - df_sum:
            column: [total_register_knight_zc,have_order_knight,single_daily_order]
        - df_reset_index: []
        - push_dataset:
            key: mini
        - use_df:
            key: mini
        - fetch_cols:
            columns: [supplier_id,city_name,meta_day,have_order_knight,single_daily_order]
        - run_py:
            - |
              df = to_df(df)
              need = df.groupby(by=['city_name']).apply(lambda x: x.sort_values(by=['meta_day'])).reset_index(drop=True)
              need_result = need.groupby(by=['city_name']).cumsum().rename(columns={'have_order_knight':'total_have_order_knight','single_daily_order':'total_order','meta_day':'meta_day_other'})
              need = pd.merge(need,need_result,left_index=True,right_index=True,how='inner')
              need['days'] = need['meta_day'].map(str).str[6:8].map(int)
              need['total_utility'] = np.round(need['total_order'] / need['total_have_order_knight'],2)
              need['avg_daily_knight'] = need['total_have_order_knight'] / need['days']
              result = to_dd(need)
        - stash_push_df: []
        - use_df:
            key: mini
            columns: [supplier_id,city_name,meta_day,total_register_knight_zc]
        - stash_push_df: []
        - stash_join_df:
            on: [supplier_id,city_name,meta_day]
            how: inner
            drop_stash: true
        - fetch_cols:
            columns: [supplier_id,city_name,meta_day,total_register_knight_zc,total_order,total_utility,avg_daily_knight]


    - name: mt_total_details_city_median
      sync_result: true
      cooks:
        - fetch_dataset:
            template_code: mt_day_58          #单日城市数据
            dataset_cate: raw
            columns: [ 加盟商ID,注册骑手数,有完成单骑手数,完成单量,人效（完成订单）,meta_day ]
            ignore_null_error: true
            empty_df_record:
              加盟商ID: '-'
              注册骑手数: 1
              有完成单骑手数: 1
              完成单量: 1
              meta_day: 99999999
            rename:
              加盟商ID: alliance_id
              注册骑手数: register_knight_zc
              有完成单骑手数: have_order_knight
              完成单量: single_daily_order
        - df_to_int:
            - register_knight_zc
        - df_to_int:
            - have_order_knight
        - df_to_int:
            - single_daily_order
        - stash_push_df: [ ]
        - use_df:
            key: mt_total_details_dc
            columns: [ supplier_id,city_name,alliance_id ]
        - drop_duplicates:
            subset: [ supplier_id,city_name,alliance_id ]
        - stash_push_df: [ ]
        - stash_join_df:
            on: [ alliance_id ]
            how: inner
            drop_stash: true
        - df_groupby:
            by: [ supplier_id,city_name,meta_day ]
        - df_sum:
            column: [ single_daily_order,have_order_knight,register_knight_zc ]
        - df_reset_index: []
        - run_py:
            - |
              df = to_df(df)
              df['single_utility'] = np.round(df['single_daily_order'] / df['have_order_knight'],2)
              result = to_dd(df)
        - stash_push_df: [ ]

        - use_df:
            key: mt_city_cum_month
        - stash_push_df: [ ]
        - stash_join_df:
            on: [ supplier_id,city_name,meta_day ]
            how: outer
            drop_stash: true
        - stash_push_df: [ ]

        ###  （城市级别 ）  入职人数  离职人数  商圈数量  累计离职人数  累计入职人数
        - use_df:
            key: mt_total_details_dc
            columns: [supplier_id,supplier_name,city_name,meta_day,entry_knight,leave_knight,dc_count,total_leave_knight,total_entry_knight]
        - df_groupby:
            by:  [supplier_id,supplier_name,city_name,meta_day]
        - df_sum:
            column: [entry_knight,leave_knight,dc_count,total_leave_knight,total_entry_knight]
        - df_reset_index: []
        - stash_push_df: []
        - stash_join_df:
            on: [supplier_id,city_name,meta_day]
            how:  inner
            drop_stash: true
        - df_to_int:
            - register_knight_zc
        - df_to_int:
            - total_leave_knight
        - df_to_int:
            - total_register_knight_zc
        - df_eval:
            - |
              [register_knight] = [register_knight_zc] + [total_leave_knight]
              [total_register_knight] = [total_register_knight_zc] + [total_leave_knight]
        - stash_push_df: []

        # 计算星级
        - use_df:
            key: mt_total_details_dc
            columns: [supplier_id,supplier_name,city_name,meta_day,star_level,over_order_no_sub]
        - df_eval:
            - |
              [star_level_muti_order]  = [star_level]* [over_order_no_sub]
        - df_groupby:
            by: [ supplier_id,supplier_name,city_name,meta_day ]
        - df_sum:
            column: [ star_level_muti_order, over_order_no_sub]
        - df_reset_index: [ ]
        - df_eval:
            - |
              [weight_star_level] = [star_level_muti_order] / [over_order_no_sub]
        - fetch_cols:
            columns: [ supplier_id,supplier_name,city_name,meta_day,weight_star_level]
        - df_rename_columns:
            - weight_star_level: star_level
        - stash_push_df: []
        - stash_join_df:
            on: [supplier_id,supplier_name,city_name,meta_day]
            how: inner
            drop_stash: true

        - df_eval:
            - |
              [have_order_ratio] = [have_order_knight] / [register_knight]
              [entry_ratio] = [entry_knight] / [register_knight]
              [leave_ratio] = [leave_knight] / [register_knight]
              [total_leave_ratio] = [total_leave_knight] / [total_register_knight]
              [total_entry_ratio] = [total_entry_knight] / [total_register_knight]
        - run_py:
            - |
              df = to_df(df)
              df['days'] = df['meta_day'].map(str).str[6:8].map(int)
              result = to_dd(df)
        - df_eval:
            - |
              [avg_daily_order] = [total_order] / [days]
#        - stash_push_df: [ ]
        - add_cols:
            - dimension: 'C'
        - push_dataset:
            key: mt_total_details_city_mini

        - df_select:
            - '[supplier_id] in @p1'
            - p1: [ '5b9738f4ce6d2abdaed16a8e','5b9738f5ce6d2abdaed16e09' ]
        ### 总参与排名城市数、 全量单排名、日单量排名、日均单排名、 日均骑手量排名、当日人效排名、累计人效排名、星级排名、日留存排名
        - run_py:
            - |
              df = to_df(df)
              total_rank_count = df[["total_order","single_daily_order","avg_daily_order","avg_daily_knight","single_utility","total_utility","meta_day"]].groupby(by=['meta_day']).count().reset_index().rename(columns={"total_order":"total_order_join_rank_count","single_daily_order":"single_daily_order_join_rank_count","avg_daily_order":"avg_daily_order_join_rank_count","avg_daily_knight":"avg_daily_knight_join_rank_count","single_utility":"single_utility_join_rank_count","total_utility":"total_utility_join_rank_count"})
              df = pd.merge(df,total_rank_count,on=['meta_day'],how='left',sort=False)
              df['total_order_rank'] = df.groupby(by=['meta_day'])['total_order'].rank(method='min',ascending=False)
              df['single_daily_order_rank'] = df.groupby(by=['meta_day'])['single_daily_order'].rank(method='min',ascending=False)
              df['avg_daily_order_rank'] = df.groupby(by=['meta_day'])['avg_daily_order'].rank(method='min',ascending=False)
              df['avg_daily_knight_rank'] = df.groupby(by=['meta_day'])['avg_daily_knight'].rank(method='min',ascending=False)
              df['single_utility_rank'] = df.groupby(by=['meta_day'])['single_utility'].rank(method='min',ascending=False)
              df['total_utility_rank'] = df.groupby(by=['meta_day'])['total_utility'].rank(method='min',ascending=False)
              df['star_level_rank'] = df.groupby(by=['meta_day'])['star_level'].rank(method='min',ascending=False)
              df['daily_stay_ratio'] = 1 - df['total_leave_ratio']
              df['daily_stay_ratio_rank'] = df.groupby(by=['meta_day'])['daily_stay_ratio'].rank(method='min',ascending=False)
              result =  to_dd(df)
        - push_dataset:
            key: mt_total_details_city_mini_yjd_and_rd
        - stash_push_df: [ ]

        - use_df:
            key: mt_total_details_city_mini
        - df_select:
            - '[supplier_id] == @p1'
            - p1: '5c8f38ae887d1f1c43bfc06e'
        ### 总参与排名城市数、 全量单排名、日单量排名、日均单排名、 日均骑手量排名、当日人效排名、累计人效排名、星级排名、日留存排名
        - run_py:
            - |
              df = to_df(df)
              total_rank_count = df[["total_order","single_daily_order","avg_daily_order","avg_daily_knight","single_utility","total_utility","meta_day"]].groupby(by=['meta_day']).count().reset_index().rename(columns={"total_order":"total_order_join_rank_count","single_daily_order":"single_daily_order_join_rank_count","avg_daily_order":"avg_daily_order_join_rank_count","avg_daily_knight":"avg_daily_knight_join_rank_count","single_utility":"single_utility_join_rank_count","total_utility":"total_utility_join_rank_count"})
              df = pd.merge(df,total_rank_count,on=['meta_day'],how='left',sort=False)
              df['total_order_rank'] = df.groupby(by=['meta_day'])['total_order'].rank(method='min',ascending=False)
              df['single_daily_order_rank'] = df.groupby(by=['meta_day'])['single_daily_order'].rank(method='min',ascending=False)
              df['avg_daily_order_rank'] = df.groupby(by=['meta_day'])['avg_daily_order'].rank(method='min',ascending=False)
              df['avg_daily_knight_rank'] = df.groupby(by=['meta_day'])['avg_daily_knight'].rank(method='min',ascending=False)
              df['single_utility_rank'] = df.groupby(by=['meta_day'])['single_utility'].rank(method='min',ascending=False)
              df['total_utility_rank'] = df.groupby(by=['meta_day'])['total_utility'].rank(method='min',ascending=False)
              df['star_level_rank'] = df.groupby(by=['meta_day'])['star_level'].rank(method='min',ascending=False)
              df['daily_stay_ratio'] = 1 - df['total_leave_ratio']
              df['daily_stay_ratio_rank'] = df.groupby(by=['meta_day'])['daily_stay_ratio'].rank(method='min',ascending=False)
              result =  to_dd(df)
        - push_dataset:
            key: mt_total_details_city_mini_xd
        - stash_push_df: [ ]
        - stash_concat_df:
            drop_stash: true

    - name: mt_total_details_city
      sync_result: true
      cooks:
        - use_df:
            key: mt_total_details_city_median
            columns: [supplier_id,city_name,meta_day,total_order_rank,single_daily_order_rank,avg_daily_order,avg_daily_order_rank,avg_daily_knight,avg_daily_knight_rank,single_utility,single_utility_rank,total_utility,total_utility_rank]
        - df_rename_columns:
            - total_order_rank: total_order_rank_before
              single_daily_order_rank: single_daily_order_rank_before
              avg_daily_order: avg_daily_order_before
              avg_daily_order_rank: avg_daily_order_rank_before
              avg_daily_knight: avg_daily_knight_before
              avg_daily_knight_rank: avg_daily_knight_rank_before
              single_utility: single_utility_before
              single_utility_rank: single_utility_rank_before
              total_utility: total_utility_before
              total_utility_rank: total_utility_rank_before
        - run_py:
            - |
              df['meta_day'] = df['meta_day'] + 1
              result =  df
        - stash_push_df: []

        - use_df:
            key: mt_total_details_city_median
        - stash_push_df: []
        - stash_join_df:
            on: [supplier_id,city_name,meta_day]
            how: left
            drop_stash: true
        ### 全量单排名状态
        - add_cols:
            - total_order_rank_status: '-'
        - df_set_column_val_if:
            column: total_order_rank_status
            condition: '[total_order_rank] > [total_order_rank_before]'
            val: 'down'
        - df_set_column_val_if:
            column: total_order_rank_status
            condition: '[total_order_rank] < [total_order_rank_before]'
            val: 'up'
        - df_set_column_val_if:
            column: total_order_rank_status
            condition: '[total_order_rank] == [total_order_rank_before]'
            val: 'equal'
        ###  日单量排名状态
        - add_cols:
            - single_daily_order_rank_status: '-'
        - df_set_column_val_if:
            column: single_daily_order_rank_status
            condition: '[single_daily_order_rank] > [single_daily_order_rank_before]'
            val: 'down'
        - df_set_column_val_if:
            column: single_daily_order_rank_status
            condition: '[single_daily_order_rank] < [single_daily_order_rank_before]'
            val: 'up'
        - df_set_column_val_if:
            column: single_daily_order_rank_status
            condition: '[single_daily_order_rank] == [single_daily_order_rank_before]'
            val: 'equal'
        ### 日均单排名状态
        - add_cols:
            - avg_daily_order_rank_status: '-'
        - df_set_column_val_if:
            column: avg_daily_order_rank_status
            condition: '[avg_daily_order_rank] > [avg_daily_order_rank_before]'
            val: 'down'
        - df_set_column_val_if:
            column: avg_daily_order_rank_status
            condition: '[avg_daily_order_rank] < [avg_daily_order_rank_before]'
            val: 'up'
        - df_set_column_val_if:
            column: avg_daily_order_rank_status
            condition: '[avg_daily_order_rank] == [avg_daily_order_rank_before]'
            val: 'equal'
        ### 日均骑手量排名状态
        - add_cols:
            - avg_daily_knight_rank_status: '-'
        - df_set_column_val_if:
            column: avg_daily_knight_rank_status
            condition: '[avg_daily_knight_rank] > [avg_daily_knight_rank_before]'
            val: 'down'
        - df_set_column_val_if:
            column: avg_daily_knight_rank_status
            condition: '[avg_daily_knight_rank] < [avg_daily_knight_rank_before]'
            val: 'up'
        - df_set_column_val_if:
            column: avg_daily_knight_rank_status
            condition: '[avg_daily_knight_rank] == [avg_daily_knight_rank_before]'
            val: 'equal'
        ### 当日人效排名状态
        - add_cols:
            - single_utility_rank_status: '-'
        - df_set_column_val_if:
            column: single_utility_rank_status
            condition: '[single_utility_rank] > [single_utility_rank_before]'
            val: 'down'
        - df_set_column_val_if:
            column: single_utility_rank_status
            condition: '[single_utility_rank] < [single_utility_rank_before]'
            val: 'up'
        - df_set_column_val_if:
            column: single_utility_rank_status
            condition: '[single_utility_rank] == [single_utility_rank_before]'
            val: 'equal'
        ### 累计人效排名状态
        - add_cols:
            - total_utility_rank_status: '-'
        - df_set_column_val_if:
            column: total_utility_rank_status
            condition: '[total_utility_rank] > [total_utility_rank_before]'
            val: 'down'
        - df_set_column_val_if:
            column: total_utility_rank_status
            condition: '[total_utility_rank] < [total_utility_rank_before]'
            val: 'up'
        - df_set_column_val_if:
            column: total_utility_rank_status
            condition: '[total_utility_rank] == [total_utility_rank_before]'
            val: 'equal'


        ### 日均单环比增长, 日均骑手量环比增长,当日人效环比增长 ,累计人效环比增长
        - df_eval:
            - |
              [avg_daily_order_year_ratio] = ([avg_daily_order] - [avg_daily_order_before]) / [avg_daily_order_before]
              [avg_daily_knight_year_ratio] = ([avg_daily_knight] - [avg_daily_knight_before]) / [avg_daily_knight_before]
              [single_utility_year_ratio] = ([single_utility] - [single_utility_before]) / [single_utility_before]
              [total_utility_year_ratio] = ([total_utility] - [total_utility_before]) / [total_utility_before]
      ### 日均单环比状态
        - add_cols:
            - avg_daily_order_year_ratio_status: '-'
        - df_set_column_val_if:
            column: avg_daily_order_year_ratio_status
            condition: '[avg_daily_order_year_ratio] > 0'
            val: 'up'
        - df_set_column_val_if:
            column: avg_daily_order_year_ratio_status
            condition: '[avg_daily_order_year_ratio] < 0 '
            val: 'down'
        - df_set_column_val_if:
            column: avg_daily_order_year_ratio_status
            condition: '[avg_daily_order_year_ratio] == 0'
            val: 'equal'
      ### 日均骑手量环比状态
        - add_cols:
            - avg_daily_knight_year_ratio_status: '-'
        - df_set_column_val_if:
            column: avg_daily_knight_year_ratio_status
            condition: '[avg_daily_knight_year_ratio] > 0'
            val: 'up'
        - df_set_column_val_if:
            column: avg_daily_knight_year_ratio_status
            condition: '[avg_daily_knight_year_ratio] < 0 '
            val: 'down'
        - df_set_column_val_if:
            column: avg_daily_knight_year_ratio_status
            condition: '[avg_daily_knight_year_ratio] == 0'
            val: 'equal'
      ### 当日人效环比状态
        - add_cols:
            - single_utility_year_ratio_status: '-'
        - df_set_column_val_if:
            column: single_utility_year_ratio_status
            condition: '[single_utility_year_ratio] > 0'
            val: 'up'
        - df_set_column_val_if:
            column: single_utility_year_ratio_status
            condition: '[single_utility_year_ratio] < 0 '
            val: 'down'
        - df_set_column_val_if:
            column: single_utility_year_ratio_status
            condition: '[single_utility_year_ratio] == 0'
            val: 'equal'
      ###累计人效环比状态
        - add_cols:
            - total_utility_year_ratio_status: '-'
        - df_set_column_val_if:
            column: total_utility_year_ratio_status
            condition: '[total_utility_year_ratio] > 0'
            val: 'up'
        - df_set_column_val_if:
            column: total_utility_year_ratio_status
            condition: '[total_utility_year_ratio] < 0 '
            val: 'down'
        - df_set_column_val_if:
            column: total_utility_year_ratio_status
            condition: '[total_utility_year_ratio] == 0'
            val: 'equal'

        - fetch_cols:
            columns: [supplier_id,supplier_name,city_name,meta_day,dimension,total_join_rank_count,dc_count,total_order,single_daily_order,single_daily_order_rank,single_daily_order_rank_status,total_order_rank,total_order_rank_status,avg_daily_order,avg_daily_order_rank,avg_daily_order_rank_status,avg_daily_order_year_ratio,avg_daily_order_year_ratio_status,avg_daily_knight,avg_daily_knight_rank,avg_daily_knight_rank_status,avg_daily_knight_year_ratio,avg_daily_knight_year_ratio_status,single_utility,single_utility_rank,single_utility_rank_status,single_utility_year_ratio,total_utility,total_utility_year_ratio,total_utility_year_ratio_status,total_utility_rank,total_utility_rank_status,single_utility_year_ratio_status,have_order_knight,have_order_ratio,entry_knight,entry_ratio,leave_knight,leave_ratio,star_level,star_level_rank,daily_stay_ratio_rank,daily_stay_ratio,total_leave_ratio,total_entry_ratio,total_order_join_rank_count,single_daily_order_join_rank_count,avg_daily_order_join_rank_count,avg_daily_knight_join_rank_count,single_utility_join_rank_count,total_utility_join_rank_count]
        - set_meta_month_column:
            - book_month

## 总体详情
    - name: mt_total_details
      sync_result: true
      cooks:
        - use_df:
            key: mt_total_details_dc
        - stash_push_df: []

        - use_df:
            key: mt_total_details_city
        - stash_push_df: []

        - stash_concat_df:
            drop_stash: true
        - df_rename_columns:
            - meta_day: book_day
        - df_to_int:
            - book_day

### 历史星级KPI
    - name: mt_star_level_and_kpi_tendency
      sync_result: true
      cooks:
        - fetch_dataset:
            dataset_type_code: mt_total_details
            dataset_cate: std
            month_offset: -1
            ignore_null_error: true
            empty_df_record:
              supplier_name: '-'
              supplier_id: '-'
              city_name: '-'
              vendor_dc_id: '-'
              dc_name: '-'
              book_month: 999999
              book_day: 19790101
              dimension: '-'
              star_level: 0.0
              kpi_score: 0.0
              total_utility: 0.0
              avg_daily_order: 0.0
              star_level_rank: 0
              daily_stay_ratio_rank: 0
              daily_stay_ratio: 0.0
              total_leave_ratio: 0.0
              total_entry_ratio: 0.0
        - run_py:
            - |
              df = df[df['book_day'] == df['book_day'].max()]
              result = df
        - stash_push_df: []
        - fetch_dataset:
            dataset_type_code: mt_total_details
            dataset_cate: std
            month_offset: -2
            ignore_null_error: true
            empty_df_record:
              supplier_name: '-'
              supplier_id: '-'
              city_name: '-'
              vendor_dc_id: '-'
              dc_name: '-'
              book_month: 999999
              book_day: 19790101
              dimension: '-'
              star_level: 0.0
              kpi_score: 0.0
              total_utility: 0.0
              avg_daily_order: 0.0
              star_level_rank: 0
              daily_stay_ratio_rank: 0
              daily_stay_ratio: 0.0
              total_leave_ratio: 0.0
              total_entry_ratio: 0.0
        - run_py:
            - |
              df = df[df['book_day'] == df['book_day'].max()]
              result = df
        - stash_push_df: []
        - fetch_dataset:
            dataset_type_code: mt_total_details
            dataset_cate: std
            month_offset: -3
            ignore_null_error: true
            empty_df_record:
              supplier_name: '-'
              supplier_id: '-'
              city_name: '-'
              vendor_dc_id: '-'
              dc_name: '-'
              book_month: 999999
              book_day: 19790101
              dimension: '-'
              star_level: 0.0
              kpi_score: 0.0
              total_utility: 0.0
              avg_daily_order: 0.0
              star_level_rank: 0
              daily_stay_ratio_rank: 0
              daily_stay_ratio: 0.0
              total_leave_ratio: 0.0
              total_entry_ratio: 0.0
        - run_py:
            - |
              df = df[df['book_day'] == df['book_day'].max()]
              result = df
        - stash_push_df: []
        - fetch_dataset:
            dataset_type_code: mt_total_details
            dataset_cate: std
            month_offset: -4
            ignore_null_error: true
            empty_df_record:
              supplier_name: '-'
              supplier_id: '-'
              city_name: '-'
              vendor_dc_id: '-'
              dc_name: '-'
              book_month: 999999
              book_day: 19790101
              dimension: '-'
              star_level: 0.0
              kpi_score: 0.0
              total_utility: 0.0
              avg_daily_order: 0.0
              star_level_rank: 0
              daily_stay_ratio_rank: 0
              daily_stay_ratio: 0.0
              total_leave_ratio: 0.0
              total_entry_ratio: 0.0
        - run_py:
            - |
              df = df[df['book_day'] == df['book_day'].max()]
              result = df
        - stash_push_df: []
        - fetch_dataset:
            dataset_type_code: mt_total_details
            dataset_cate: std
            month_offset: -5
            ignore_null_error: true
            empty_df_record:
              supplier_name: '-'
              supplier_id: '-'
              city_name: '-'
              vendor_dc_id: '-'
              dc_name: '-'
              book_month: 999999
              book_day: 19790101
              dimension: '-'
              star_level: 0.0
              kpi_score: 0.0
              total_utility: 0.0
              avg_daily_order: 0.0
              star_level_rank: 0
              daily_stay_ratio_rank: 0
              daily_stay_ratio: 0.0
              total_leave_ratio: 0.0
              total_entry_ratio: 0.0
        - run_py:
            - |
              df = df[df['book_day'] == df['book_day'].max()]
              result = df
        - stash_push_df: []
        - fetch_dataset:
            dataset_type_code: mt_total_details
            dataset_cate: std
            month_offset: -6
            ignore_null_error: true
            empty_df_record:
              supplier_name: '-'
              supplier_id: '-'
              city_name: '-'
              vendor_dc_id: '-'
              dc_name: '-'
              book_month: 999999
              book_day: 19790101
              dimension: '-'
              star_level: 0.0
              kpi_score: 0.0
              total_utility: 0.0
              avg_daily_order: 0.0
              star_level_rank: 0
              daily_stay_ratio_rank: 0
              daily_stay_ratio: 0.0
              total_leave_ratio: 0.0
              total_entry_ratio: 0.0
        - run_py:
            - |
              df = df[df['book_day'] == df['book_day'].max()]
              result = df
        - stash_push_df: []
        - fetch_dataset:
            dataset_type_code: mt_total_details
            dataset_cate: std
            month_offset: -7
            ignore_null_error: true
            empty_df_record:
              supplier_name: '-'
              supplier_id: '-'
              city_name: '-'
              vendor_dc_id: '-'
              dc_name: '-'
              book_month: 999999
              book_day: 19790101
              dimension: '-'
              star_level: 0.0
              kpi_score: 0.0
              total_utility: 0.0
              avg_daily_order: 0.0
              star_level_rank: 0
              daily_stay_ratio_rank: 0
              daily_stay_ratio: 0.0
              total_leave_ratio: 0.0
              total_entry_ratio: 0.0
        - run_py:
            - |
              df = df[df['book_day'] == df['book_day'].max()]
              result = df
        - stash_push_df: []
        - fetch_dataset:
            dataset_type_code: mt_total_details
            dataset_cate: std
            month_offset: -8
            ignore_null_error: true
            empty_df_record:
              supplier_name: '-'
              supplier_id: '-'
              city_name: '-'
              vendor_dc_id: '-'
              dc_name: '-'
              book_month: 999999
              book_day: 19790101
              dimension: '-'
              star_level: 0.0
              kpi_score: 0.0
              total_utility: 0.0
              avg_daily_order: 0.0
              star_level_rank: 0
              daily_stay_ratio_rank: 0
              daily_stay_ratio: 0.0
              total_leave_ratio: 0.0
              total_entry_ratio: 0.0
        - run_py:
            - |
              df = df[df['book_day'] == df['book_day'].max()]
              result = df
        - stash_push_df: []
        - fetch_dataset:
            dataset_type_code: mt_total_details
            dataset_cate: std
            month_offset: -9
            ignore_null_error: true
            empty_df_record:
              supplier_name: '-'
              supplier_id: '-'
              city_name: '-'
              vendor_dc_id: '-'
              dc_name: '-'
              book_month: 999999
              book_day: 19790101
              dimension: '-'
              star_level: 0.0
              kpi_score: 0.0
              total_utility: 0.0
              avg_daily_order: 0.0
              star_level_rank: 0
              daily_stay_ratio_rank: 0
              daily_stay_ratio: 0.0
              total_leave_ratio: 0.0
              total_entry_ratio: 0.0
        - run_py:
            - |
              df = df[df['book_day'] == df['book_day'].max()]
              result = df
        - stash_push_df: []
        - fetch_dataset:
            dataset_type_code: mt_total_details
            dataset_cate: std
            month_offset: -10
            ignore_null_error: true
            empty_df_record:
              supplier_name: '-'
              supplier_id: '-'
              city_name: '-'
              vendor_dc_id: '-'
              dc_name: '-'
              book_month: 999999
              book_day: 19790101
              dimension: '-'
              star_level: 0.0
              kpi_score: 0.0
              total_utility: 0.0
              avg_daily_order: 0.0
              star_level_rank: 0
              daily_stay_ratio_rank: 0
              daily_stay_ratio: 0.0
              total_leave_ratio: 0.0
              total_entry_ratio: 0.0
        - run_py:
            - |
              df = df[df['book_day'] == df['book_day'].max()]
              result = df
        - stash_push_df: []
        - fetch_dataset:
            dataset_type_code: mt_total_details
            dataset_cate: std
            month_offset: -11
            ignore_null_error: true
            empty_df_record:
              supplier_name: '-'
              supplier_id: '-'
              city_name: '-'
              vendor_dc_id: '-'
              dc_name: '-'
              book_month: 999999
              book_day: 19790101
              dimension: '-'
              star_level: 0.0
              kpi_score: 0.0
              total_utility: 0.0
              avg_daily_order: 0.0
              star_level_rank: 0
              daily_stay_ratio_rank: 0
              daily_stay_ratio: 0.0
              total_leave_ratio: 0.0
              total_entry_ratio: 0.0
        - run_py:
            - |
              df = df[df['book_day'] == df['book_day'].max()]
              result = df
        - stash_push_df: []
        - fetch_dataset:
            dataset_type_code: mt_total_details
            dataset_cate: std
            month_offset: -12
            ignore_null_error: true
            empty_df_record:
              supplier_name: '-'
              supplier_id: '-'
              city_name: '-'
              vendor_dc_id: '-'
              dc_name: '-'
              book_month: 999999
              book_day: 19790101
              dimension: '-'
              star_level: 0.0
              kpi_score: 0.0
              total_utility: 0.0
              avg_daily_order: 0.0
              star_level_rank: 0
              daily_stay_ratio_rank: 0
              daily_stay_ratio: 0.0
              total_leave_ratio: 0.0
              total_entry_ratio: 0.0
        - stash_push_df: []
        - use_df:
            key: mt_total_details
            columns: [supplier_name,supplier_id,city_name,vendor_dc_id,dc_name,book_month,book_day,dimension,star_level,kpi_score,total_utility,avg_daily_order,star_level_rank,daily_stay_ratio_rank,daily_stay_ratio,total_leave_ratio,total_entry_ratio]
        - run_py:
            - |
              df = to_df(df)
              max_day = df['book_day'].max()
              df = df[df['book_day'] == max_day]
              result = to_dd(df)
        - fetch_cols:
            columns: [supplier_name,supplier_id,city_name,vendor_dc_id,dc_name,book_month,dimension,star_level,kpi_score,total_utility,avg_daily_order,star_level_rank,daily_stay_ratio_rank,daily_stay_ratio,total_leave_ratio,total_entry_ratio]
        - stash_push_df: []
        - stash_concat_df:
            drop_stash: true


### 骑手影响站点分布
    - name: mt_knight_affect_dc_score
      sync_result: true
      cooks:
        - fetch_dataset:
            template_code: mt_day_18      #单日骑手数据
            dataset_cate: raw
            columns: [ 骑手ID,站点ID,站点,完成单量,在岗时长,meta_day]
            ignore_null_error: true
            empty_df_record:
              骑手ID: '-'
              站点ID: '-'
              站点: '-'
              完成单量: 0
              在岗时长: 0.0
              meta_day: '-'
            rename:
              骑手ID: knight_id
              站点ID: vendor_dc_id
              站点: dc_name
              完成单量: single_daily_order
              在岗时长: on_guard_time
        - add_cols:
            - attendance: 0
        - df_set_column_val_if:
            column: attendance
            condition: '[single_daily_order] == 0 '
            val: 0
            else_val: 1
        - run_py:
            - |
              df = to_df(df)
              need = df.groupby(by=['vendor_dc_id','knight_id'])['attendance'].sum().reset_index()
              max_day = df['meta_day'].max()
              df_max_day = df[df['meta_day'] == max_day ][['vendor_dc_id','dc_name','knight_id','single_daily_order','on_guard_time','meta_day']]
              df = pd.merge(df_max_day,need,on=['vendor_dc_id','knight_id'],how='left',sort=False)
              df['days'] = df['meta_day'].map(str).str[6:8].map(int)
              df['attendance_ratio'] = df['attendance'] / df['days']
              result = to_dd(df)
        - add_cols:
            - daily_order_not_standard_count: 0
              on_guard_time_not_standard_count: 0
              attendance_not_standard_count: 0
              get_standard_count: 0
              total_knight: 1
        - df_set_column_val_if:
            column: daily_order_not_standard_count
            condition: '[single_daily_order] < 9 '
            val: 1
            else_val: 0
        - df_set_column_val_if:
            column: on_guard_time_not_standard_count
            condition: '[on_guard_time] <  180 '
            val: 1
            else_val: 0
        - df_set_column_val_if:
            column: attendance_not_standard_count
            condition: '[attendance_ratio] < 0.75 '
            val: 1
            else_val: 0
        - df_set_column_val_if:
            column: get_standard_count
            condition: '([on_guard_time_not_standard_count] != 1) & ([daily_order_not_standard_count] != 1) & ([attendance_not_standard_count] != 1)'
            val: 1
            else_val: 0
        - df_groupby:
            by: [ vendor_dc_id,dc_name,meta_day]
        - df_sum:
            column: [daily_order_not_standard_count,on_guard_time_not_standard_count,attendance_not_standard_count,get_standard_count,total_knight]
        - df_reset_index: []
        - df_eval:
            - |
              [low_standard_count] = [total_knight] - [get_standard_count]
              [get_standard_count_ratio] = [get_standard_count] / [total_knight]
              [low_standard_count_ratio] = 1 - [get_standard_count_ratio]
        - stash_push_df: []

        - fetch_dataset:
            dataset_type_code: std_qplus_dc
            dataset_cate: std
            columns: [ platform_code,supplier_id,supplier_name,city_name,vendor_dc_id ]
            ignore_null_error: true
        - when_empty_fetch_dataset:
            dataset_type_code: std_qplus_dc
            dataset_cate: std
            columns: [ platform_code,supplier_id,supplier_name,city_name,vendor_dc_id ]
            month_offset: -1
            ignore_null_error: true
        - drop_duplicates:
            subset: [ platform_code,supplier_id,vendor_dc_id ]
        - df_select:
            - '[platform_code] == @p1'
            - p1: meituan
        - stash_push_df: [ ]
        - stash_join_df:
            on: [ vendor_dc_id ]
            how: inner
            drop_stash: true
        - add_cols:
            - dimension: 'D'

## 权限——基础数据表
    - name: mt_authority_raw_data
      sync_result: true
      cooks:
        - fetch_dataset:
            template_code: mt_day_35        #单日站点数据
            dataset_cate: raw
            columns: [ 站点id,meta_day,meta_month ]
            ignore_null_error: true
            empty_df_record:
              站点id: '-'
              meta_day: '-'
              meta_month: '-'
            rename:
              站点id: vendor_dc_id
        - drop_duplicates:
            subset: [vendor_dc_id, meta_month]
        - fetch_cols:
            columns: [ vendor_dc_id,meta_month]

    - name: mt_kpi_detail
      sync_result: true
      cooks:
        - fetch_dataset:
            template_code: mt_day_13
            dataset_cate: raw
            datakit_pull_way: last_day
            ignore_null_error: true
            empty_df_record:
              加盟站ID: 0
              加盟站名称: '-'
              完成单(未剔除异常单): 0
              星级: 0
              得分: 0
              提前点送达(复合)订单数: 0
              15分钟超时订单数: 0
              不满意订单数: 0
              配送原因未完成数: 0
              一般超时单量(考核): 0
              严重超时单量(考核): 0
              提前点送达率(复合): 0.0%
              15分钟超时订单占比: 0.0%
              不满意率: 0.0%
              配送原因未完成率: 0.0%
              复合准时率（考核）: 0.0%
              meta_day: 99999999
              meta_month: 999999
            columns:
              - 加盟站ID
              - 加盟站名称
              - 完成单(未剔除异常单)
              - 星级
              - 得分
              - 提前点送达(复合)订单数
              - 15分钟超时订单数
              - 不满意订单数
              - 配送原因未完成数
              - 一般超时单量(考核)
              - 严重超时单量(考核)
              - 提前点送达率(复合)
              - 15分钟超时订单占比
              - 不满意率
              - 配送原因未完成率
              - 复合准时率（考核）
              - meta_day
              - meta_month
            rename:
              加盟站ID: vendor_dc_id
              加盟站名称: dc_name
              完成单(未剔除异常单): total_order
              星级: star_level
              得分: total_score
              提前点送达(复合)订单数: advance_delivery_orders
              15分钟超时订单数: over_15_orders
              不满意订单数: dissatisfy_orders
              配送原因未完成数: unfinished_orders
              一般超时单量(考核): ordinary_over_time_orders
              严重超时单量(考核): serious_over_time_orders
              提前点送达率(复合): advance_delivery_ratio
              15分钟超时订单占比: over_15_ratio
              不满意率: dissatisfy_ratio
              配送原因未完成率: unfinished_ratio
              复合准时率（考核）: punctuality_ratio
              meta_day: book_day
              meta_month: book_month
        - add_cols:
            - advance_delivery_score: 0
        - add_cols:
            - over_15_ratio_score: 0
        - add_cols:
            - dissatisfy_ratio_score: 0
        - add_cols:
            - unfinished_ratio_score: 0
        - add_cols:
            - punctuality_ratio_score: 0
        - add_cols:
            - avg_daily_order: 0
        - add_cols:
            - punctuality_contains: 0
        - add_cols:
            - punctuality_surplus: 0
        - add_cols:
            - advance_delivery_contains: 0
        - add_cols:
            - advance_delivery_surplus: 0
        - add_cols:
            - over_15_contains: 0
        - add_cols:
            - over_15_surplus: 0
        - add_cols:
            - dissatisfy_contains: 0
        - add_cols:
            - dissatisfy_surplus: 0
        - add_cols:
            - unfinished_contains: 0
        - add_cols:
            - unfinished_surplus: 0
        - df_to_float:
            - advance_delivery_score
        - df_to_float:
            - over_15_ratio_score
        - df_to_float:
            - dissatisfy_ratio_score
        - df_to_float:
            - unfinished_ratio_score
        - df_to_float:
            - punctuality_ratio_score
        - df_to_float:
            - avg_daily_order
        - df_to_float:
            - punctuality_contains
        - df_to_float:
            - punctuality_surplus
        - df_to_float:
            - advance_delivery_contains
        - df_to_float:
            - advance_delivery_surplus
        - df_to_float:
            - over_15_contains
        - df_to_float:
            - over_15_surplus
        - df_to_float:
            - dissatisfy_contains
        - df_to_float:
            - dissatisfy_surplus
        - df_to_float:
            - unfinished_contains
        - df_to_float:
            - unfinished_surplus
        - str_strip_column:
            column: advance_delivery_ratio
            char: '%'
        - df_to_float:
            - advance_delivery_ratio
        - df_eval:
            - '[advance_delivery_ratio] = [advance_delivery_ratio] / 100'
        - str_strip_column:
            column: over_15_ratio
            char: '%'
        - df_to_float:
            - over_15_ratio
        - df_eval:
            - '[over_15_ratio] = [over_15_ratio] / 100'
        - str_strip_column:
            column: dissatisfy_ratio
            char: '%'
        - df_to_float:
            - dissatisfy_ratio
        - df_eval:
            - '[dissatisfy_ratio] = [dissatisfy_ratio] / 100'
        - str_strip_column:
            column: unfinished_ratio
            char: '%'
        - df_to_float:
            - unfinished_ratio
        - df_eval:
            - '[unfinished_ratio] = [unfinished_ratio] / 100'
        - str_strip_column:
            column: punctuality_ratio
            char: '%'
        - df_to_float:
            - punctuality_ratio
        - df_eval:
            - '[punctuality_ratio] = [punctuality_ratio] / 100'
        - df_to_int:
            - vendor_dc_id
        - run_py:
            - |
              df=to_df(df)
              df['vendor_dc_id']=[u'%s' % i for i in df[u'vendor_dc_id']]
              result=to_dd(df)
        - stash_push_df: []
        - fetch_dataset:
            template_code: mt_month_60
            dataset_cate: raw
            ignore_null_error: true
            empty_df_record:
              站点ID: '-'
              复合准时率X: 0.0%
              复合准时率Y: 0.0%
              复合准时率Z: 0.0%
              配送原因未完成率X: 0.0%
              配送原因未完成率Y: 0.0%
              配送原因未完成率Z: 0.0%
              不满意率X: 0.0%
              不满意率Y: 0.0%
              不满意率Z: 0.0%
              提前点送达率X: 0.0%
              提前点送达率Y: 0.0%
              提前点送达率Z: 0.0%
              15分钟超时订单占比X: 0.0%
              15分钟超时订单占比Y: 0.0%
              15分钟超时订单占比Z: 0.0%
            columns:
              - 站点ID
              - 复合准时率X
              - 复合准时率Y
              - 复合准时率Z
              - 配送原因未完成率X
              - 配送原因未完成率Y
              - 配送原因未完成率Z
              - 不满意率X
              - 不满意率Y
              - 不满意率Z
              - 提前点送达率X
              - 提前点送达率Y
              - 提前点送达率Z
              - 15分钟超时订单占比X
              - 15分钟超时订单占比Y
              - 15分钟超时订单占比Z
            rename:
              站点ID: vendor_dc_id
              复合准时率X: X1
              复合准时率Y: Y1
              复合准时率Z: Z1
              配送原因未完成率X: X2
              配送原因未完成率Y: Y2
              配送原因未完成率Z: Z2
              不满意率X: X3
              不满意率Y: Y3
              不满意率Z: Z3
              提前点送达率X: X4
              提前点送达率Y: Y4
              提前点送达率Z: Z4
              15分钟超时订单占比X: X5
              15分钟超时订单占比Y: Y5
              15分钟超时订单占比Z: Z5
        - str_strip_column:
            column: X1
            char: '%'
        - df_to_float:
            - X1
        - df_eval:
            - '[X1] = [X1] / 100'
        - str_strip_column:
            column: Y1
            char: '%'
        - df_to_float:
            - Y1
        - df_eval:
            - '[Y1] = [Y1] / 100'
        - str_strip_column:
            column: Z1
            char: '%'
        - df_to_float:
            - Z1
        - df_eval:
            - '[Z1] = [Z1] / 100'
        - str_strip_column:
            column: X2
            char: '%'
        - df_to_float:
            - X2
        - df_eval:
            - '[X2] = [X2] / 100'
        - str_strip_column:
            column: Y2
            char: '%'
        - df_to_float:
            - Y2
        - df_eval:
            - '[Y2] = [Y2] / 100'
        - str_strip_column:
            column: Z2
            char: '%'
        - df_to_float:
            - Z2
        - df_eval:
            - '[Z2] = [Z2] / 100'
        - str_strip_column:
            column: X3
            char: '%'
        - df_to_float:
            - X3
        - df_eval:
            - '[X3] = [X3] / 100'
        - str_strip_column:
            column: Y3
            char: '%'
        - df_to_float:
            - Y3
        - df_eval:
            - '[Y3] = [Y3] / 100'
        - str_strip_column:
            column: Z3
            char: '%'
        - df_to_float:
            - Z3
        - df_eval:
            - '[Z3] = [Z3] / 100'
        - str_strip_column:
            column: X4
            char: '%'
        - df_to_float:
            - X4
        - df_eval:
            - '[X4] = [X4] / 100'
        - str_strip_column:
            column: Y4
            char: '%'
        - df_to_float:
            - Y4
        - df_eval:
            - '[Y4] = [Y4] / 100'
        - str_strip_column:
            column: Z4
            char: '%'
        - df_to_float:
            - Z4
        - df_eval:
            - '[Z4] = [Z4] / 100'
        - str_strip_column:
            column: X5
            char: '%'
        - df_to_float:
            - X5
        - df_eval:
            - '[X5] = [X5] / 100'
        - str_strip_column:
            column: Y5
            char: '%'
        - df_to_float:
            - Y5
        - df_eval:
            - '[Y5] = [Y5] / 100'
        - str_strip_column:
            column: Z5
            char: '%'
        - df_to_float:
            - Z5
        - df_eval:
            - '[Z5] = [Z5] / 100'
        - df_to_int:
            - vendor_dc_id
        - run_py:
            - |
              df=to_df(df)
              df['vendor_dc_id']=[u'%s' % i for i in df[u'vendor_dc_id']]
              result=to_dd(df)
        - stash_push_df: []
        - stash_join_df:
            how: right
            on: vendor_dc_id
            fillna: 0
            drop_stash: True
        - set_meta_days_column:
            - 当月总天数
        - run_py:
            - |
              df=to_df(df)
              df['days'] = df['book_day'].map(str).str[6:8].map(int)
              result = to_dd(df)
        - push_dataset:
            key: mt_kpi_detail_mini

###提前点送达得分
        - use_df:
            key: mt_kpi_detail_mini
        - df_select:
            - '[advance_delivery_ratio] > [X4]'
        - df_eval:
            - '[advance_delivery_score] = 0'
        - stash_push_df: []
        - use_df:
            key: mt_kpi_detail_mini
        - df_select:
            - '[advance_delivery_ratio] <= [X4] & [advance_delivery_ratio] > [Y4]'
        - df_eval:
            - '[advance_delivery_score] = 100* ([advance_delivery_ratio]-[X4])/([Y4]-[X4])'
        - stash_push_df: []
        - use_df:
            key: mt_kpi_detail_mini
        - df_select:
            - '[advance_delivery_ratio] <= [Y4] & [advance_delivery_ratio] > [Z4]'
        - df_eval:
            - '[advance_delivery_score] = 100+20* ([advance_delivery_ratio]-[Y4])/([Z4]-[Y4])'
        - stash_push_df: []
        - use_df:
            key: mt_kpi_detail_mini
        - df_select:
            - '[advance_delivery_ratio] <= [Z4]'
        - df_eval:
            - '[advance_delivery_score] = 120'
        - stash_push_df: []
        - stash_concat_df:
            drop_stash: True
        - push_dataset:
            key: mt_kpi_detail_mini

###15分钟超时占比得分
        - use_df:
            key: mt_kpi_detail_mini
        - df_select:
            - '[over_15_ratio] > [X5]'
        - df_eval:
            - '[over_15_ratio_score] = 0'
        - stash_push_df: []
        - use_df:
            key: mt_kpi_detail_mini
        - df_select:
            - '[over_15_ratio] <= [X5] & [over_15_ratio] > [Y5]'
        - df_eval:
            - '[over_15_ratio_score] = 100* ([over_15_ratio]-[X5])/([Y5]-[X5])'
        - stash_push_df: []
        - use_df:
            key: mt_kpi_detail_mini
        - df_select:
            - '[over_15_ratio] <= [Y5] & [over_15_ratio] > [Z5]'
        - df_eval:
            - '[over_15_ratio_score] = 100+20* ([over_15_ratio]-[Y5])/([Z5]-[Y5])'
        - stash_push_df: []
        - use_df:
            key: mt_kpi_detail_mini
        - df_select:
            - '[over_15_ratio] <= [Z5]'
        - df_eval:
            - '[over_15_ratio_score] = 120'
        - stash_push_df: []
        - stash_concat_df:
            drop_stash: True
        - push_dataset:
            key: mt_kpi_detail_mini

###不满意率得分
        - use_df:
            key: mt_kpi_detail_mini
        - df_select:
            - '[dissatisfy_ratio] > [X3]'
        - df_eval:
            - '[dissatisfy_ratio_score] = 0'
        - stash_push_df: []
        - use_df:
            key: mt_kpi_detail_mini
        - df_select:
            - '[dissatisfy_ratio] <= [X3] & [dissatisfy_ratio] > [Y3]'
        - df_eval:
            - '[dissatisfy_ratio_score] = 100* ([dissatisfy_ratio]-[X3])/([Y3]-[X3])'
        - stash_push_df: []
        - use_df:
            key: mt_kpi_detail_mini
        - df_select:
            - '[dissatisfy_ratio] <= [Y3] & [dissatisfy_ratio] > [Z3]'
        - df_eval:
            - '[dissatisfy_ratio_score] = 100+20* ([dissatisfy_ratio]-[Y3])/([Z3]-[Y3])'
        - stash_push_df: []
        - use_df:
            key: mt_kpi_detail_mini
        - df_select:
            - '[dissatisfy_ratio] <= [Z3]'
        - df_eval:
            - '[dissatisfy_ratio_score] = 120'
        - stash_push_df: []
        - stash_concat_df:
            drop_stash: True
        - push_dataset:
            key: mt_kpi_detail_mini

###配送原因未完成率得分
        - use_df:
            key: mt_kpi_detail_mini
        - df_select:
            - '[unfinished_ratio] > [X2]'
        - df_eval:
            - '[unfinished_ratio_score] = 0'
        - stash_push_df: []
        - use_df:
            key: mt_kpi_detail_mini
        - df_select:
            - '[unfinished_ratio] <= [X2] & [unfinished_ratio] > [Y2]'
        - df_eval:
            - '[unfinished_ratio_score] = 100* ([unfinished_ratio]-[X2])/([Y2]-[X2])'
        - stash_push_df: []
        - use_df:
            key: mt_kpi_detail_mini
        - df_select:
            - '[unfinished_ratio] <= [Y2] & [unfinished_ratio] > [Z2]'
        - df_eval:
            - '[unfinished_ratio_score] = 100+20* ([unfinished_ratio]-[Y2])/([Z2]-[Y2])'
        - stash_push_df: []
        - use_df:
            key: mt_kpi_detail_mini
        - df_select:
            - '[unfinished_ratio] <= [Z2]'
        - df_eval:
            - '[unfinished_ratio_score] = 120'
        - stash_push_df: []
        - stash_concat_df:
            drop_stash: True
        - push_dataset:
            key: mt_kpi_detail_mini

###复合准时率得分
        - use_df:
            key: mt_kpi_detail_mini
        - df_select:
            - '[punctuality_ratio] < [X1]'
        - df_eval:
            - '[punctuality_ratio_score] = 0'
        - stash_push_df: []
        - use_df:
            key: mt_kpi_detail_mini
        - df_select:
            - '[punctuality_ratio] >= [X1] & [punctuality_ratio] < [Y1]'
        - df_eval:
            - '[punctuality_ratio_score] = 100* ([punctuality_ratio]-[X1])/([Y1]-[X1])'
        - stash_push_df: []
        - use_df:
            key: mt_kpi_detail_mini
        - df_select:
            - '[punctuality_ratio] >= [Y1] & [punctuality_ratio] < [Z1]'
        - df_eval:
            - '[punctuality_ratio_score] = 100+20* ([punctuality_ratio]-[Y1])/([Z1]-[Y1])'
        - stash_push_df: []
        - use_df:
            key: mt_kpi_detail_mini
        - df_select:
            - '[punctuality_ratio] >= [Z1]'
        - df_eval:
            - '[punctuality_ratio_score] = 120'
        - stash_push_df: []
        - stash_concat_df:
            drop_stash: True
###日均单
        - df_eval:
            - '[avg_daily_order] = [total_order]/[days]'

###复合配送准时（容错值）& 复合配送准时（余量）
        - df_to_int:
            - ordinary_over_time_orders
        - df_to_int:
            - serious_over_time_orders
        - df_eval:
            - '[punctuality_contains] = [avg_daily_order]*[当月总天数]*(1 - [Z1])'
        - df_eval:
            - '[punctuality_surplus] = [punctuality_contains] - 1*[ordinary_over_time_orders] - 5*[serious_over_time_orders]'

###提前点送达单量（容错值）& 提前点送达单量（余量）
        - df_to_int:
            - advance_delivery_orders
        - df_eval:
            - '[advance_delivery_contains] = [avg_daily_order]*[当月总天数]*[Z4]'
        - df_eval:
            - '[advance_delivery_surplus] = [advance_delivery_contains] - [advance_delivery_orders]'

###15分钟超时单量（容错值）& 15分钟超时单量（余量）
        - df_to_int:
            - over_15_orders
        - df_eval:
            - '[over_15_contains] = [avg_daily_order]*[当月总天数]*[Z5]'
        - df_eval:
            - '[over_15_surplus] = [over_15_contains] - [over_15_orders]'
###不满意单量（容错值）& 不满意单量（余量）
        - df_to_int:
            - dissatisfy_orders
        - df_eval:
            - '[dissatisfy_contains] = [avg_daily_order]*[当月总天数]*[Z3]'
        - df_eval:
            - '[dissatisfy_surplus] = [dissatisfy_contains] - [dissatisfy_orders]'

###配送原因未完成单量（容错值）& 配送原因未完成单量（余量）
        - df_to_int:
            - unfinished_orders
        - df_eval:
            - '[unfinished_contains] = [avg_daily_order]*[当月总天数]*[Z2]'
        - df_eval:
            - '[unfinished_surplus] = [unfinished_contains] - [unfinished_orders]'
        - stash_push_df: []
        - fetch_dataset:
            dataset_type_code: std_qplus_dc
            dataset_cate: std
            ignore_null_error: true
            columns:
              - supplier_id
              - vendor_dc_id
              - city_name
              - supplier_name
        - when_empty_fetch_dataset:
            dataset_type_code: std_qplus_dc
            dataset_cate: std
            month_offset: -1
            ignore_null_error: true
            columns:
              - supplier_id
              - vendor_dc_id
              - city_name
              - supplier_name
        - drop_duplicates:
            subset: [ supplier_id,vendor_dc_id ,city_name ]
        - stash_push_df: []
        - stash_join_df:
            on: [ vendor_dc_id ]
            how: right
            drop_stash: true
### score
    - name: mt_kpi_detail_score
      sync_result: true
      cooks:
        - use_df:
            key: mt_kpi_detail
            columns:
              - supplier_name
              - supplier_id
              - city_name
              - dc_name
              - vendor_dc_id
              - book_month
              - book_day
              - star_level
              - total_score
              - advance_delivery_score
              - over_15_ratio_score
              - dissatisfy_ratio_score
              - unfinished_ratio_score
              - punctuality_ratio_score
            rename:
              star_level: 星级结果
              total_score: 总分
              advance_delivery_score: 提前点送达得分
              over_15_ratio_score: 15分钟超时占比得分
              dissatisfy_ratio_score: 不满意率得分
              unfinished_ratio_score: 配送原因未完成率得分
              punctuality_ratio_score: 复核准时率得分

### orders
    - name: mt_kpi_detail_orders
      sync_result: true
      cooks:
        - use_df:
            key: mt_kpi_detail
            columns:
              - supplier_name
              - supplier_id
              - city_name
              - dc_name
              - vendor_dc_id
              - book_month
              - book_day
              - advance_delivery_orders
              - over_15_orders
              - dissatisfy_orders
              - unfinished_orders
              - ordinary_over_time_orders
              - serious_over_time_orders
            rename:
              advance_delivery_orders: 提前点送达单量
              over_15_orders: 15分钟超时单量
              dissatisfy_orders: 不满意单量
              unfinished_orders: 配送原因未完成单量
              ordinary_over_time_orders: 一般超时单量
              serious_over_time_orders: 严重超时单量

### ratio
    - name: mt_kpi_detail_ratio
      sync_result: true
      cooks:
        - use_df:
            key: mt_kpi_detail
            columns:
              - supplier_name
              - supplier_id
              - city_name
              - dc_name
              - vendor_dc_id
              - book_month
              - book_day
              - advance_delivery_ratio
              - over_15_ratio
              - dissatisfy_ratio
              - unfinished_ratio
              - punctuality_ratio
            rename:
              advance_delivery_ratio: 提前点送达率
              over_15_ratio: 15分钟超时率
              dissatisfy_ratio: 不满意率
              unfinished_ratio: 配送原因未完成率
              punctuality_ratio: 复核准时率

### contains
    - name: mt_kpi_detail_contains
      sync_result: true
      cooks:
        - use_df:
            key: mt_kpi_detail
            columns:
              - supplier_name
              - supplier_id
              - city_name
              - dc_name
              - vendor_dc_id
              - book_month
              - book_day
              - punctuality_contains
              - punctuality_surplus
              - advance_delivery_contains
              - advance_delivery_surplus
              - over_15_contains
              - over_15_surplus
              - dissatisfy_contains
              - dissatisfy_surplus
              - unfinished_contains
              - unfinished_surplus

            rename:
              punctuality_contains: 复核配送准时（容错值）
              punctuality_surplus: 复核配送准时（余量）
              advance_delivery_contains: 提前点送达单量（容错值）
              advance_delivery_surplus: 提前点送达单量（余量）
              over_15_contains: 15分钟超时单量（容错值）
              over_15_surplus: 15分钟超时单量（余量）
              dissatisfy_contains: 不满意单量（容错值）
              dissatisfy_surplus: 不满意单量（余量）
              unfinished_contains: 配送原因未完成单量（容错值）
              unfinished_surplus: 配送原因未完成单量（余量）


    - name: mt_knight_detail
      sync_result: true
      cooks:
        - fetch_dataset:
            template_code: mt_day_18
            dataset_cate: raw
            ignore_null_error: true
            empty_df_record:
              骑手ID: '-'
              骑手: '-'
              站点ID: '-'
              站点: '-'
              骑手接单量: 0
              完成单量: 0
              在岗时长: 0
              meta_day: 0
              meta_month: 0
            columns:
              - 骑手ID
              - 骑手
              - 站点ID
              - 站点
              - 骑手接单量
              - 完成单量
              - 在岗时长
              - meta_day
              - meta_month
            rename:
              骑手ID: knight_id
              骑手: knight_name
              站点ID: vendor_dc_id
              站点: dc_name
              完成单量: avg_daily_order
              在岗时长: on_guard_time
              meta_day: book_day
              meta_month: book_month
        - add_cols:
            - attendance: 0 #出勤率
        - add_cols:
            - avg_daily_order_std_line: 9
        - add_cols:
            - on_guard_time_std_line: 180
        - add_cols:
            - attendance_std_line: 0.75
        - run_py:
            - |
              df=to_df(df)
              df['max_days']=df['book_day'].max()
              df['days'] = df['max_days'].map(str).str[6:8].map(int)
              result = to_dd(df)
        - push_dataset:
            key: mt_day_18_knight_detail
        - use_df:
            key: mt_day_18_knight_detail
        - stash_push_df: []
        - fetch_dataset:
            dataset_type_code: std_qplus_dc
            dataset_cate: std
            ignore_null_error: true
            columns:
              - supplier_id
              - vendor_dc_id
              - city_name
              - supplier_name
        - when_empty_fetch_dataset:
            dataset_type_code: std_qplus_dc
            dataset_cate: std
            month_offset: -1
            ignore_null_error: true
            columns:
              - supplier_id
              - vendor_dc_id
              - city_name
              - supplier_name
        - drop_duplicates:
            subset: [ supplier_id,vendor_dc_id ,city_name ]
        - stash_push_df: []
        - stash_join_df:
            on: [ vendor_dc_id ]
            how: right
            drop_stash: true
        - stash_push_df: []

###骑手出勤率
        - use_df:
            key: mt_day_18_knight_detail
        - add_cols:
            - 出勤天数: 1
        - df_select:
            - '[avg_daily_order] > 0'
        - df_groupby:
            by: [vendor_dc_id,knight_id]
        - df_sum:
            column: [出勤天数]
        - df_reset_index: []
        - stash_push_df: []
        - stash_join_df:
            on: [vendor_dc_id,knight_id]
            how: right
            drop_stash: true
        - df_eval:
            - '[attendance] = [出勤天数] / [days]'
        - run_py:
            - |
              df = to_df(df)
              df=df[df['book_day']==df['book_day'].max()]
              result = to_dd(df)



mt_month_env:
  context_defaults:
    delay_compute: true
    sync_result_from_cluster: true
    play_on_dask_cluster: true
    platform_code: meituan
    dask_client_set_as_default: true
    cluster_client_address: 'dask-scheduler-service.databus:8786'

  play:
    - name: mt_dc_cum_month    #月累计站点数据
      sync_result: true
      cooks:
        - fetch_dataset:
            template_code: mt_day_35        #日累计站点数据
            dataset_cate: raw
            datakit_pull_way: last_day
            columns: [ 站点id,注册骑手数,离职骑手数,入职骑手数,有完成单骑手数,完成单量,人效（完成订单）,meta_day ]
            ignore_null_error: true
            empty_df_record:
              站点id: '-'
              注册骑手数: 1
              离职骑手数: 1
              入职骑手数: 1
              有完成单骑手数: 1
              完成单量: 1
              meta_day: 99999999
              人效（完成订单）: 0.0
            rename:
              站点id: vendor_dc_id
              注册骑手数: register_knight #register_knight
              离职骑手数: total_leave_knight #leave_knight
              入职骑手数: total_entry_knight #entry_knight
              有完成单骑手数: total_have_order_knight #have_order_knight
              完成单量: total_order  #single_daily_order
              人效（完成订单）: total_utility
        - df_to_int:
            - register_knight
        - df_to_int:
            - total_leave_knight
        - df_to_int:
            - total_entry_knight
        - df_to_int:
            - total_have_order_knight
        - df_to_int:
            - total_order
        - df_to_float:
            - total_utility
        - df_eval:
            - |
              [total_register_knight] = [register_knight] + [total_leave_knight]
        - fetch_cols:
            columns: [vendor_dc_id,meta_day,total_register_knight,total_leave_knight,total_entry_knight,total_order,total_utility]
        - stash_push_df: []
        - fetch_dataset:
            template_code: mt_day_61        #单日站点数据
            dataset_cate: raw
            columns: [ 站点id,有完成单骑手数,meta_day ]
            ignore_null_error: true
            empty_df_record:
              站点id: '-'
              有完成单骑手数: 1
              meta_day: 99999999
            rename:
              站点id: vendor_dc_id
              有完成单骑手数: have_order_knight
        - df_to_int:
            - have_order_knight
        - run_py:
            - |
              df = to_df(df)
              need = df.groupby(by=['vendor_dc_id']).apply(lambda x: x.sort_values(by=['meta_day'])).reset_index(drop=True)
              need_result = need.groupby(by=['vendor_dc_id']).cumsum().rename(columns={'have_order_knight':'total_have_order_knight','meta_day':'meta_day_other'})
              need = pd.merge(need,need_result,left_index=True,right_index=True,how='inner')
              need_days = need.groupby(by=['vendor_dc_id'])['meta_day'].count().reset_index().rename(columns={'meta_day':'days'})
              need = pd.merge(need,need_days,how ='inner',on=['vendor_dc_id'])
              need['avg_daily_knight'] = need['total_have_order_knight'] / need['days']
              result = to_dd(need)
        - fetch_cols:
            columns: [vendor_dc_id,meta_day,avg_daily_knight]
        - stash_push_df: []
        - stash_join_df:
            on: [vendor_dc_id,meta_day]
            how: outer
            drop_stash: true
        - fetch_cols:
            columns: [vendor_dc_id,meta_day,total_register_knight,total_leave_knight,total_entry_knight,total_order,total_utility,avg_daily_knight]


    - name: mt_total_details_dc_median
      sync_result: true
      cooks:
        - fetch_dataset:
            template_code: mt_day_61        #单日站点数据
            dataset_cate: raw
            columns: [站点名称,站点id,注册骑手数,离职骑手数,入职骑手数,有完成单骑手数,完成单量,人效（完成订单）,加盟商ID,meta_day]
            ignore_null_error: true
            empty_df_record:
              站点名称: '-'
              站点id: '-'
              注册骑手数: 1
              离职骑手数: 1
              入职骑手数: 1
              有完成单骑手数: 1
              完成单量: 1
              人效（完成订单）: 1.0
              加盟商ID: '-'
              meta_day: 99999999
            rename:
              站点名称: dc_name
              站点id: vendor_dc_id
              注册骑手数: register_knight_zc
              离职骑手数: leave_knight
              入职骑手数: entry_knight
              有完成单骑手数: have_order_knight
              完成单量: single_daily_order
              人效（完成订单）: single_utility
              加盟商ID: alliance_id
        - df_to_int:
            - register_knight_zc
        - df_to_int:
            - leave_knight
        - df_to_int:
            - entry_knight
        - df_to_int:
            - have_order_knight
        - df_to_int:
            - single_daily_order
        - df_to_float:
            - single_utility
        - fetch_cols:
            columns: [dc_name,vendor_dc_id,register_knight_zc,leave_knight,entry_knight,have_order_knight,single_daily_order,single_utility,alliance_id,meta_day]
        - stash_push_df: []

        - use_df:
            key: mt_dc_cum_month

        - stash_push_df: []
        - stash_join_df:
            on: [vendor_dc_id,meta_day]
            how: outer
            drop_stash: true
        - df_to_int:
            - total_leave_knight
        - df_eval:
            - |
              [register_knight] = [register_knight_zc] + [total_leave_knight]
        - stash_push_df: []
        - fetch_dataset:
            template_code: mt_day_13    # 日星级结果
            dataset_cate: raw
            columns: [加盟站ID,加盟站名称,得分,星级,完成单(未剔除异常单),meta_day]
            ignore_null_error: true
            empty_df_record:
              加盟站名称: '-'
              加盟站ID: '-'
              得分: 0.0
              星级: 0.0
              完成单(未剔除异常单): 0
              meta_day: 99999999
            rename:
              加盟站名称: dc_name
              加盟站ID: vendor_dc_id
              得分: kpi_score
              星级: star_level
              完成单(未剔除异常单): over_order_no_sub
        - df_to_int:
            - over_order_no_sub
        - df_to_float:
            - kpi_score
        - df_to_float:
            - star_level
        - stash_push_df: []
        - stash_join_df:
            on: [vendor_dc_id,dc_name,meta_day]
            how: outer
            drop_stash: true
        - df_to_float:
            - have_order_knight
        - df_to_float:
            - register_knight
        - df_to_float:
            - entry_knight
        - df_to_float:
            - leave_knight
        - df_to_float:
            - total_entry_knight
        - df_to_float:
            - total_register_knight
        - df_to_float:
            - total_leave_knight

        - run_py:
            - |
              df['have_order_ratio'] = df['have_order_knight'] / df['register_knight']
              df['entry_ratio'] = df['entry_knight'] / df['register_knight']
              df['leave_ratio'] = df['leave_knight'] / df['register_knight']
              df['total_entry_ratio'] = df['total_entry_knight'] /  df['total_register_knight']
              df['total_leave_ratio'] = df['total_leave_knight'] / df['total_register_knight']
              result = df
        - fetch_cols:
            columns: [meta_day,vendor_dc_id,dc_name,over_order_no_sub,kpi_score,star_level,avg_daily_knight,total_order,total_leave_knight,total_entry_knight,total_register_knight,total_utility,leave_knight,have_order_knight,alliance_id,single_utility,single_daily_order,entry_knight,register_knight_zc,register_knight,have_order_ratio,entry_ratio,leave_ratio,total_entry_ratio,total_leave_ratio]
        - stash_push_df: []

        - fetch_dataset:
            template_code: mt_day_59     # AA站点难度等级明细
            dataset_cate: raw
            columns: [站点ID,难度等级]
            ignore_null_error: true
            empty_df_record:
              站点ID: '-'
              难度等级: '-'
            rename:
              站点ID: vendor_dc_id
              难度等级: difficulty_level
        - stash_push_df:  []
        - stash_join_df:
            on: [vendor_dc_id]
            how: outer
            drop_stash: true

        - run_py:
            - |
              df = to_df(df)
              df_days = df.groupby(by=['vendor_dc_id'])['meta_day'].count().reset_index().rename(columns={'meta_day':'days'})
              df = pd.merge(df,df_days,how ='inner',on=['vendor_dc_id'])
              result = to_dd(df)
#              df['days'] = df['meta_day'].map(str).str[6:].map(int)
        - df_to_int:
            - total_order
        - df_eval:
            - |
              [avg_daily_order] = [total_order] / [days]
        - stash_push_df: []

        - fetch_dataset:
            dataset_type_code: std_qplus_dc
            dataset_cate: std
            columns: [platform_code,supplier_id,supplier_name,city_name,vendor_dc_id]
            ignore_null_error: true
        - when_empty_fetch_dataset:
            dataset_type_code: std_qplus_dc
            dataset_cate: std
            columns: [platform_code,supplier_id,supplier_name,city_name,vendor_dc_id]
            month_offset: -1
            ignore_null_error: true
        - drop_duplicates:
            subset: [ platform_code,supplier_id,vendor_dc_id  ]
        - df_select:
            - '[platform_code] == @p1'
            - p1: meituan
        - stash_push_df: []
        - stash_join_df:
            on: [vendor_dc_id]
            how: inner
            drop_stash: true
        - add_cols:
            - dc_count: 1
              dimension: 'D'
        - push_dataset:
            key: mt_total_details_dc_mini

        - df_select:
            - '[supplier_id] in @p1'
            - p1: ['5b9738f4ce6d2abdaed16a8e','5b9738f5ce6d2abdaed16e09']
        ### 总参与排名商圈数、 全量单排名、日单量排名、日均单排名、 日均骑手量排名、当日人效排名、累计人效排名、KPI得分排名、星级排名、日留存排名
        - run_py:
            - |
              df = to_df(df)
              total_rank_count = df[["total_order","single_daily_order","avg_daily_order","avg_daily_knight","single_utility","total_utility","meta_day"]].groupby(by=['meta_day']).count().reset_index().rename(columns={"total_order":"total_order_join_rank_count","single_daily_order":"single_daily_order_join_rank_count","avg_daily_order":"avg_daily_order_join_rank_count","avg_daily_knight":"avg_daily_knight_join_rank_count","single_utility":"single_utility_join_rank_count","total_utility":"total_utility_join_rank_count"})
              df = pd.merge(df,total_rank_count,on=['meta_day'],how='left',sort=False)
              df['total_order_rank'] = df.groupby(by=['meta_day'])['total_order'].rank(method='min',ascending=False)
              df['single_daily_order_rank'] = df.groupby(by=['meta_day'])['single_daily_order'].rank(method='min',ascending=False)
              df['avg_daily_order_rank'] = df.groupby(by=['meta_day'])['avg_daily_order'].rank(method='min',ascending=False)
              df['avg_daily_knight_rank'] = df.groupby(by=['meta_day'])['avg_daily_knight'].rank(method='min',ascending=False)
              df['single_utility_rank'] = df.groupby(by=['meta_day'])['single_utility'].rank(method='min',ascending=False)
              df['total_utility_rank'] = df.groupby(by=['meta_day'])['total_utility'].rank(method='min',ascending=False)
              df['kpi_score_rank'] = df.groupby(by=['meta_day'])['kpi_score'].rank(method='min',ascending=False)
              df['star_level_rank'] = df.groupby(by=['meta_day'])['star_level'].rank(method='min',ascending=False)
              df['daily_stay_ratio'] = 1 - df['total_leave_ratio']
              df['daily_stay_ratio_rank'] = df.groupby(by=['meta_day'])['daily_stay_ratio'].rank(method='min',ascending=False)
              result =  to_dd(df)
        - push_dataset:
            key: mt_total_details_dc_mini_yjd_and_rd
        - stash_push_df: []

        - use_df:
            key: mt_total_details_dc_mini
        - df_select:
            - '[supplier_id] == @p1'
            - p1: '5c8f38ae887d1f1c43bfc06e'
        ### 总参与排名商圈数、 全量单排名、日单量排名、日均单排名、 日均骑手量排名、当日人效排名、累计人效排名、KPI得分排名、星级排名、日留存排名
        - run_py:
            - |
              df = to_df(df)
              total_rank_count = df[["total_order","single_daily_order","avg_daily_order","avg_daily_knight","single_utility","total_utility","meta_day"]].groupby(by=['meta_day']).count().reset_index().rename(columns={"total_order":"total_order_join_rank_count","single_daily_order":"single_daily_order_join_rank_count","avg_daily_order":"avg_daily_order_join_rank_count","avg_daily_knight":"avg_daily_knight_join_rank_count","single_utility":"single_utility_join_rank_count","total_utility":"total_utility_join_rank_count"})
              df = pd.merge(df,total_rank_count,on=['meta_day'],how='left',sort=False)
              df['total_order_rank'] = df.groupby(by=['meta_day'])['total_order'].rank(method='min',ascending=False)
              df['single_daily_order_rank'] = df.groupby(by=['meta_day'])['single_daily_order'].rank(method='min',ascending=False)
              df['avg_daily_order_rank'] = df.groupby(by=['meta_day'])['avg_daily_order'].rank(method='min',ascending=False)
              df['avg_daily_knight_rank'] = df.groupby(by=['meta_day'])['avg_daily_knight'].rank(method='min',ascending=False)
              df['single_utility_rank'] = df.groupby(by=['meta_day'])['single_utility'].rank(method='min',ascending=False)
              df['total_utility_rank'] = df.groupby(by=['meta_day'])['total_utility'].rank(method='min',ascending=False)
              df['kpi_score_rank'] = df.groupby(by=['meta_day'])['kpi_score'].rank(method='min',ascending=False)
              df['star_level_rank'] = df.groupby(by=['meta_day'])['star_level'].rank(method='min',ascending=False)
              df['daily_stay_ratio'] = 1 - df['total_leave_ratio']
              df['daily_stay_ratio_rank'] = df.groupby(by=['meta_day'])['daily_stay_ratio'].rank(method='min',ascending=False)
              result =  to_dd(df)
        - push_dataset:
            key: mt_total_details_dc_mini_xd
        - stash_push_df: []
        - stash_concat_df:
            drop_stash: true

    - name: mt_total_details_dc
      sync_result: true
      cooks:
        - use_df:
            key: mt_total_details_dc_median
            columns: [supplier_id,vendor_dc_id,meta_day,total_order_rank,single_daily_order_rank,avg_daily_order,avg_daily_order_rank,avg_daily_knight,avg_daily_knight_rank,single_utility,single_utility_rank,total_utility,total_utility_rank]
        - df_rename_columns:
            - total_order_rank: total_order_rank_before
              single_daily_order_rank: single_daily_order_rank_before
              avg_daily_order: avg_daily_order_before
              avg_daily_order_rank: avg_daily_order_rank_before
              avg_daily_knight: avg_daily_knight_before
              avg_daily_knight_rank: avg_daily_knight_rank_before
              single_utility: single_utility_before
              single_utility_rank: single_utility_rank_before
              total_utility: total_utility_before
              total_utility_rank: total_utility_rank_before
        - run_py:
            - |
              df['meta_day'] = df['meta_day'] + 1
              result = df
        - stash_push_df: []

        - use_df:
            key: mt_total_details_dc_median
        - stash_push_df: []
        - stash_join_df:
            on: [supplier_id,vendor_dc_id,meta_day]
            how: left
            drop_stash: true
        ### 全量单排名状态
        - add_cols:
            - total_order_rank_status: '-'
        - df_set_column_val_if:
            column: total_order_rank_status
            condition: '[total_order_rank] > [total_order_rank_before]'
            val: 'down'
        - df_set_column_val_if:
            column: total_order_rank_status
            condition: '[total_order_rank] < [total_order_rank_before]'
            val: 'up'
        - df_set_column_val_if:
            column: total_order_rank_status
            condition: '[total_order_rank] == [total_order_rank_before]'
            val: 'equal'
        ###  日单量排名状态
        - add_cols:
            - single_daily_order_rank_status: '-'
        - df_set_column_val_if:
            column: single_daily_order_rank_status
            condition: '[single_daily_order_rank] > [single_daily_order_rank_before]'
            val: 'down'
        - df_set_column_val_if:
            column: single_daily_order_rank_status
            condition: '[single_daily_order_rank] < [single_daily_order_rank_before]'
            val: 'up'
        - df_set_column_val_if:
            column: single_daily_order_rank_status
            condition: '[single_daily_order_rank] == [single_daily_order_rank_before]'
            val: 'equal'
        ### 日均单排名状态
        - add_cols:
            - avg_daily_order_rank_status: '-'
        - df_set_column_val_if:
            column: avg_daily_order_rank_status
            condition: '[avg_daily_order_rank] > [avg_daily_order_rank_before]'
            val: 'down'
        - df_set_column_val_if:
            column: avg_daily_order_rank_status
            condition: '[avg_daily_order_rank] < [avg_daily_order_rank_before]'
            val: 'up'
        - df_set_column_val_if:
            column: avg_daily_order_rank_status
            condition: '[avg_daily_order_rank] == [avg_daily_order_rank_before]'
            val: 'equal'
        ### 日均骑手量排名状态
        - add_cols:
            - avg_daily_knight_rank_status: '-'
        - df_set_column_val_if:
            column: avg_daily_knight_rank_status
            condition: '[avg_daily_knight_rank] > [avg_daily_knight_rank_before]'
            val: 'down'
        - df_set_column_val_if:
            column: avg_daily_knight_rank_status
            condition: '[avg_daily_knight_rank] < [avg_daily_knight_rank_before]'
            val: 'up'
        - df_set_column_val_if:
            column: avg_daily_knight_rank_status
            condition: '[avg_daily_knight_rank] == [avg_daily_knight_rank_before]'
            val: 'equal'
        ### 当日人效排名状态
        - add_cols:
            - single_utility_rank_status: '-'
        - df_set_column_val_if:
            column: single_utility_rank_status
            condition: '[single_utility_rank] > [single_utility_rank_before]'
            val: 'down'
        - df_set_column_val_if:
            column: single_utility_rank_status
            condition: '[single_utility_rank] < [single_utility_rank_before]'
            val: 'up'
        - df_set_column_val_if:
            column: single_utility_rank_status
            condition: '[single_utility_rank] == [single_utility_rank_before]'
            val: 'equal'
        ### 累计人效排名状态
        - add_cols:
            - total_utility_rank_status: '-'
        - df_set_column_val_if:
            column: total_utility_rank_status
            condition: '[total_utility_rank] > [total_utility_rank_before]'
            val: 'down'
        - df_set_column_val_if:
            column: total_utility_rank_status
            condition: '[total_utility_rank] < [total_utility_rank_before]'
            val: 'up'
        - df_set_column_val_if:
            column: total_utility_rank_status
            condition: '[total_utility_rank] == [total_utility_rank_before]'
            val: 'equal'


        ### 日均单环比增长, 日均骑手量环比增长,当日人效环比增长 ,累计人效环比增长
        - df_eval:
            - |
              [avg_daily_order_year_ratio] = ([avg_daily_order] - [avg_daily_order_before]) / [avg_daily_order_before]
              [avg_daily_knight_year_ratio] = ([avg_daily_knight] - [avg_daily_knight_before]) / [avg_daily_knight_before]
              [single_utility_year_ratio] = ([single_utility] - [single_utility_before]) / [single_utility_before]
              [total_utility_year_ratio] = ([total_utility] - [total_utility_before]) / [total_utility_before]
      ### 日均单环比状态
        - add_cols:
            - avg_daily_order_year_ratio_status: '-'
        - df_set_column_val_if:
            column: avg_daily_order_year_ratio_status
            condition: '[avg_daily_order_year_ratio] > 0'
            val: 'up'
        - df_set_column_val_if:
            column: avg_daily_order_year_ratio_status
            condition: '[avg_daily_order_year_ratio] < 0 '
            val: 'down'
        - df_set_column_val_if:
            column: avg_daily_order_year_ratio_status
            condition: '[avg_daily_order_year_ratio] == 0'
            val: 'equal'
      ### 日均骑手量环比状态
        - add_cols:
            - avg_daily_knight_year_ratio_status: '-'
        - df_set_column_val_if:
            column: avg_daily_knight_year_ratio_status
            condition: '[avg_daily_knight_year_ratio] > 0'
            val: 'up'
        - df_set_column_val_if:
            column: avg_daily_knight_year_ratio_status
            condition: '[avg_daily_knight_year_ratio] < 0 '
            val: 'down'
        - df_set_column_val_if:
            column: avg_daily_knight_year_ratio_status
            condition: '[avg_daily_knight_year_ratio] == 0'
            val: 'equal'
      ### 当日人效环比状态
        - add_cols:
            - single_utility_year_ratio_status: '-'
        - df_set_column_val_if:
            column: single_utility_year_ratio_status
            condition: '[single_utility_year_ratio] > 0'
            val: 'up'
        - df_set_column_val_if:
            column: single_utility_year_ratio_status
            condition: '[single_utility_year_ratio] < 0 '
            val: 'down'
        - df_set_column_val_if:
            column: single_utility_year_ratio_status
            condition: '[single_utility_year_ratio] == 0'
            val: 'equal'
      ###累计人效环比状态
        - add_cols:
            - total_utility_year_ratio_status: '-'
        - df_set_column_val_if:
            column: total_utility_year_ratio_status
            condition: '[total_utility_year_ratio] > 0'
            val: 'up'
        - df_set_column_val_if:
            column: total_utility_year_ratio_status
            condition: '[total_utility_year_ratio] < 0 '
            val: 'down'
        - df_set_column_val_if:
            column: total_utility_year_ratio_status
            condition: '[total_utility_year_ratio] == 0'
            val: 'equal'

        - fetch_cols:
            columns: [supplier_id,supplier_name,city_name,vendor_dc_id,dc_name,alliance_id,meta_day,dimension,total_join_rank_count,dc_count,total_order,single_daily_order,single_daily_order_rank,single_daily_order_rank_status,total_order_rank,total_order_rank_status,avg_daily_order,avg_daily_order_rank,avg_daily_order_rank_status,avg_daily_order_year_ratio,avg_daily_order_year_ratio_status,avg_daily_knight,avg_daily_knight_rank,avg_daily_knight_rank_status,avg_daily_knight_year_ratio,avg_daily_knight_year_ratio_status,single_utility,single_utility_rank,single_utility_rank_status,single_utility_year_ratio,total_utility,total_utility_year_ratio,total_utility_year_ratio_status,total_utility_rank,total_utility_rank_status,single_utility_year_ratio_status,have_order_knight,have_order_ratio,entry_knight,entry_ratio,leave_knight,leave_ratio,kpi_score,star_level,kpi_score_rank,difficulty_level,star_level_rank,daily_stay_ratio_rank,daily_stay_ratio,over_order_no_sub,total_leave_ratio,total_entry_ratio,total_entry_knight,total_leave_knight,total_order_join_rank_count,single_daily_order_join_rank_count,avg_daily_order_join_rank_count,avg_daily_knight_join_rank_count,single_utility_join_rank_count,total_utility_join_rank_count]
        - set_meta_month_column:
            - book_month

    - name: mt_city_cum_month    # 月累计城市数据
      sync_result: true
      cooks:
        - fetch_dataset:
            template_code: mt_day_58       #单日城市数据
            dataset_cate: raw
            columns: [ 加盟商ID,注册骑手数,有完成单骑手数,完成单量,meta_day ]
            ignore_null_error: true
            empty_df_record:
              加盟商ID: '-'
              注册骑手数: 1
              有完成单骑手数: 1
              完成单量: 1
              meta_day: 99999999
            rename:
              加盟商ID: alliance_id
              注册骑手数: total_register_knight_zc
              有完成单骑手数: have_order_knight
              完成单量: single_daily_order
        - drop_duplicates:
            subset: [alliance_id,meta_day]
        - df_to_int:
            - total_register_knight_zc
        - df_to_int:
            - have_order_knight
        - df_to_int:
            - single_daily_order
        - stash_push_df: []
        - use_df:
            key: mt_total_details_dc
            columns: [ supplier_id,city_name,alliance_id ]
        - drop_duplicates:
            subset: [ supplier_id,city_name,alliance_id ]
        - stash_push_df: []
        - stash_join_df:
            on: [alliance_id]
            how: inner
            drop_stash: true
        - df_groupby:
            by: [supplier_id,city_name,meta_day]
        - df_sum:
            column: [total_register_knight_zc,have_order_knight,single_daily_order]
        - df_reset_index: []
        - push_dataset:
            key: mini
        - use_df:
            key: mini
        - fetch_cols:
            columns: [supplier_id,city_name,meta_day,have_order_knight,single_daily_order]
        - run_py:
            - |
              df = to_df(df)
              need = df.groupby(by=['city_name']).apply(lambda x: x.sort_values(by=['meta_day'])).reset_index(drop=True)
              need_result = need.groupby(by=['city_name']).cumsum().rename(columns={'have_order_knight':'total_have_order_knight','single_daily_order':'total_order','meta_day':'meta_day_other'})
              need = pd.merge(need,need_result,left_index=True,right_index=True,how='inner')
              need['days'] = need['meta_day'].map(str).str[6:8].map(int)
              need['total_utility'] = np.round(need['total_order'] / need['total_have_order_knight'],2)
              need['avg_daily_knight'] = need['total_have_order_knight'] / need['days']
              result = to_dd(need)
        - stash_push_df: []
        - use_df:
            key: mini
            columns: [supplier_id,city_name,meta_day,total_register_knight_zc]
        - stash_push_df: []
        - stash_join_df:
            on: [supplier_id,city_name,meta_day]
            how: inner
            drop_stash: true
        - fetch_cols:
            columns: [supplier_id,city_name,meta_day,total_register_knight_zc,total_order,total_utility,avg_daily_knight]


    - name: mt_total_details_city_median
      sync_result: true
      cooks:
        - fetch_dataset:
            template_code: mt_day_58          #单日城市数据
            dataset_cate: raw
            columns: [ 加盟商ID,注册骑手数,有完成单骑手数,完成单量,人效（完成订单）,meta_day ]
            ignore_null_error: true
            empty_df_record:
              加盟商ID: '-'
              注册骑手数: 1
              有完成单骑手数: 1
              完成单量: 1
              meta_day: 99999999
            rename:
              加盟商ID: alliance_id
              注册骑手数: register_knight_zc
              有完成单骑手数: have_order_knight
              完成单量: single_daily_order
        - df_to_int:
            - register_knight_zc
        - df_to_int:
            - have_order_knight
        - df_to_int:
            - single_daily_order
        - stash_push_df: [ ]
        - use_df:
            key: mt_total_details_dc
            columns: [ supplier_id,city_name,alliance_id ]
        - drop_duplicates:
            subset: [ supplier_id,city_name,alliance_id ]
        - stash_push_df: [ ]
        - stash_join_df:
            on: [ alliance_id ]
            how: inner
            drop_stash: true
        - df_groupby:
            by: [ supplier_id,city_name,meta_day ]
        - df_sum:
            column: [ single_daily_order,have_order_knight,register_knight_zc ]
        - df_reset_index: []
        - run_py:
            - |
              df = to_df(df)
              df['single_utility'] = np.round(df['single_daily_order'] / df['have_order_knight'],2)
              result = to_dd(df)
        - stash_push_df: [ ]

        - use_df:
            key: mt_city_cum_month
        - stash_push_df: [ ]
        - stash_join_df:
            on: [ supplier_id,city_name,meta_day ]
            how: outer
            drop_stash: true
        - stash_push_df: [ ]

        ###  （城市级别 ）  入职人数  离职人数  商圈数量  累计离职人数  累计入职人数
        - use_df:
            key: mt_total_details_dc
            columns: [supplier_id,supplier_name,city_name,meta_day,entry_knight,leave_knight,dc_count,total_leave_knight,total_entry_knight]
        - df_groupby:
            by:  [supplier_id,supplier_name,city_name,meta_day]
        - df_sum:
            column: [entry_knight,leave_knight,dc_count,total_leave_knight,total_entry_knight]
        - df_reset_index: []
        - stash_push_df: []
        - stash_join_df:
            on: [supplier_id,city_name,meta_day]
            how:  inner
            drop_stash: true
        - df_to_int:
            - register_knight_zc
        - df_to_int:
            - total_leave_knight
        - df_to_int:
            - total_register_knight_zc
        - df_eval:
            - |
              [register_knight] = [register_knight_zc] + [total_leave_knight]
              [total_register_knight] = [total_register_knight_zc] + [total_leave_knight]
        - stash_push_df: []

        # 计算星级
        - use_df:
            key: mt_total_details_dc
            columns: [supplier_id,supplier_name,city_name,meta_day,star_level,over_order_no_sub]
        - df_eval:
            - |
              [star_level_muti_order]  = [star_level]* [over_order_no_sub]
        - df_groupby:
            by: [ supplier_id,supplier_name,city_name,meta_day ]
        - df_sum:
            column: [ star_level_muti_order, over_order_no_sub]
        - df_reset_index: [ ]
        - df_eval:
            - |
              [weight_star_level] = [star_level_muti_order] / [over_order_no_sub]
        - fetch_cols:
            columns: [ supplier_id,supplier_name,city_name,meta_day,weight_star_level]
        - df_rename_columns:
            - weight_star_level: star_level
        - stash_push_df: []
        - stash_join_df:
            on: [supplier_id,supplier_name,city_name,meta_day]
            how: inner
            drop_stash: true

        - df_eval:
            - |
              [have_order_ratio] = [have_order_knight] / [register_knight]
              [entry_ratio] = [entry_knight] / [register_knight]
              [leave_ratio] = [leave_knight] / [register_knight]
              [total_leave_ratio] = [total_leave_knight] / [total_register_knight]
              [total_entry_ratio] = [total_entry_knight] / [total_register_knight]
        - run_py:
            - |
              df = to_df(df)
              df['days'] = df['meta_day'].map(str).str[6:8].map(int)
              result = to_dd(df)
        - df_eval:
            - |
              [avg_daily_order] = [total_order] / [days]
#        - stash_push_df: [ ]
        - add_cols:
            - dimension: 'C'
        - push_dataset:
            key: mt_total_details_city_mini

        - df_select:
            - '[supplier_id] in @p1'
            - p1: [ '5b9738f4ce6d2abdaed16a8e','5b9738f5ce6d2abdaed16e09' ]
        ### 总参与排名城市数、 全量单排名、日单量排名、日均单排名、 日均骑手量排名、当日人效排名、累计人效排名、星级排名、日留存排名
        - run_py:
            - |
              df = to_df(df)
              total_rank_count = df[["total_order","single_daily_order","avg_daily_order","avg_daily_knight","single_utility","total_utility","meta_day"]].groupby(by=['meta_day']).count().reset_index().rename(columns={"total_order":"total_order_join_rank_count","single_daily_order":"single_daily_order_join_rank_count","avg_daily_order":"avg_daily_order_join_rank_count","avg_daily_knight":"avg_daily_knight_join_rank_count","single_utility":"single_utility_join_rank_count","total_utility":"total_utility_join_rank_count"})
              df = pd.merge(df,total_rank_count,on=['meta_day'],how='left',sort=False)
              df['total_order_rank'] = df.groupby(by=['meta_day'])['total_order'].rank(method='min',ascending=False)
              df['single_daily_order_rank'] = df.groupby(by=['meta_day'])['single_daily_order'].rank(method='min',ascending=False)
              df['avg_daily_order_rank'] = df.groupby(by=['meta_day'])['avg_daily_order'].rank(method='min',ascending=False)
              df['avg_daily_knight_rank'] = df.groupby(by=['meta_day'])['avg_daily_knight'].rank(method='min',ascending=False)
              df['single_utility_rank'] = df.groupby(by=['meta_day'])['single_utility'].rank(method='min',ascending=False)
              df['total_utility_rank'] = df.groupby(by=['meta_day'])['total_utility'].rank(method='min',ascending=False)
              df['star_level_rank'] = df.groupby(by=['meta_day'])['star_level'].rank(method='min',ascending=False)
              df['daily_stay_ratio'] = 1 - df['total_leave_ratio']
              df['daily_stay_ratio_rank'] = df.groupby(by=['meta_day'])['daily_stay_ratio'].rank(method='min',ascending=False)
              result =  to_dd(df)
        - push_dataset:
            key: mt_total_details_city_mini_yjd_and_rd
        - stash_push_df: [ ]

        - use_df:
            key: mt_total_details_city_mini
        - df_select:
            - '[supplier_id] == @p1'
            - p1: '5c8f38ae887d1f1c43bfc06e'
        ### 总参与排名城市数、 全量单排名、日单量排名、日均单排名、 日均骑手量排名、当日人效排名、累计人效排名、星级排名、日留存排名
        - run_py:
            - |
              df = to_df(df)
              total_rank_count = df[["total_order","single_daily_order","avg_daily_order","avg_daily_knight","single_utility","total_utility","meta_day"]].groupby(by=['meta_day']).count().reset_index().rename(columns={"total_order":"total_order_join_rank_count","single_daily_order":"single_daily_order_join_rank_count","avg_daily_order":"avg_daily_order_join_rank_count","avg_daily_knight":"avg_daily_knight_join_rank_count","single_utility":"single_utility_join_rank_count","total_utility":"total_utility_join_rank_count"})
              df = pd.merge(df,total_rank_count,on=['meta_day'],how='left',sort=False)
              df['total_order_rank'] = df.groupby(by=['meta_day'])['total_order'].rank(method='min',ascending=False)
              df['single_daily_order_rank'] = df.groupby(by=['meta_day'])['single_daily_order'].rank(method='min',ascending=False)
              df['avg_daily_order_rank'] = df.groupby(by=['meta_day'])['avg_daily_order'].rank(method='min',ascending=False)
              df['avg_daily_knight_rank'] = df.groupby(by=['meta_day'])['avg_daily_knight'].rank(method='min',ascending=False)
              df['single_utility_rank'] = df.groupby(by=['meta_day'])['single_utility'].rank(method='min',ascending=False)
              df['total_utility_rank'] = df.groupby(by=['meta_day'])['total_utility'].rank(method='min',ascending=False)
              df['star_level_rank'] = df.groupby(by=['meta_day'])['star_level'].rank(method='min',ascending=False)
              df['daily_stay_ratio'] = 1 - df['total_leave_ratio']
              df['daily_stay_ratio_rank'] = df.groupby(by=['meta_day'])['daily_stay_ratio'].rank(method='min',ascending=False)
              result =  to_dd(df)
        - push_dataset:
            key: mt_total_details_city_mini_xd
        - stash_push_df: [ ]
        - stash_concat_df:
            drop_stash: true

    - name: mt_total_details_city
      sync_result: true
      cooks:
        - use_df:
            key: mt_total_details_city_median
            columns: [supplier_id,city_name,meta_day,total_order_rank,single_daily_order_rank,avg_daily_order,avg_daily_order_rank,avg_daily_knight,avg_daily_knight_rank,single_utility,single_utility_rank,total_utility,total_utility_rank]
        - df_rename_columns:
            - total_order_rank: total_order_rank_before
              single_daily_order_rank: single_daily_order_rank_before
              avg_daily_order: avg_daily_order_before
              avg_daily_order_rank: avg_daily_order_rank_before
              avg_daily_knight: avg_daily_knight_before
              avg_daily_knight_rank: avg_daily_knight_rank_before
              single_utility: single_utility_before
              single_utility_rank: single_utility_rank_before
              total_utility: total_utility_before
              total_utility_rank: total_utility_rank_before
        - run_py:
            - |
              df['meta_day'] = df['meta_day'] + 1
              result =  df
        - stash_push_df: []

        - use_df:
            key: mt_total_details_city_median
        - stash_push_df: []
        - stash_join_df:
            on: [supplier_id,city_name,meta_day]
            how: left
            drop_stash: true
        ### 全量单排名状态
        - add_cols:
            - total_order_rank_status: '-'
        - df_set_column_val_if:
            column: total_order_rank_status
            condition: '[total_order_rank] > [total_order_rank_before]'
            val: 'down'
        - df_set_column_val_if:
            column: total_order_rank_status
            condition: '[total_order_rank] < [total_order_rank_before]'
            val: 'up'
        - df_set_column_val_if:
            column: total_order_rank_status
            condition: '[total_order_rank] == [total_order_rank_before]'
            val: 'equal'
        ###  日单量排名状态
        - add_cols:
            - single_daily_order_rank_status: '-'
        - df_set_column_val_if:
            column: single_daily_order_rank_status
            condition: '[single_daily_order_rank] > [single_daily_order_rank_before]'
            val: 'down'
        - df_set_column_val_if:
            column: single_daily_order_rank_status
            condition: '[single_daily_order_rank] < [single_daily_order_rank_before]'
            val: 'up'
        - df_set_column_val_if:
            column: single_daily_order_rank_status
            condition: '[single_daily_order_rank] == [single_daily_order_rank_before]'
            val: 'equal'
        ### 日均单排名状态
        - add_cols:
            - avg_daily_order_rank_status: '-'
        - df_set_column_val_if:
            column: avg_daily_order_rank_status
            condition: '[avg_daily_order_rank] > [avg_daily_order_rank_before]'
            val: 'down'
        - df_set_column_val_if:
            column: avg_daily_order_rank_status
            condition: '[avg_daily_order_rank] < [avg_daily_order_rank_before]'
            val: 'up'
        - df_set_column_val_if:
            column: avg_daily_order_rank_status
            condition: '[avg_daily_order_rank] == [avg_daily_order_rank_before]'
            val: 'equal'
        ### 日均骑手量排名状态
        - add_cols:
            - avg_daily_knight_rank_status: '-'
        - df_set_column_val_if:
            column: avg_daily_knight_rank_status
            condition: '[avg_daily_knight_rank] > [avg_daily_knight_rank_before]'
            val: 'down'
        - df_set_column_val_if:
            column: avg_daily_knight_rank_status
            condition: '[avg_daily_knight_rank] < [avg_daily_knight_rank_before]'
            val: 'up'
        - df_set_column_val_if:
            column: avg_daily_knight_rank_status
            condition: '[avg_daily_knight_rank] == [avg_daily_knight_rank_before]'
            val: 'equal'
        ### 当日人效排名状态
        - add_cols:
            - single_utility_rank_status: '-'
        - df_set_column_val_if:
            column: single_utility_rank_status
            condition: '[single_utility_rank] > [single_utility_rank_before]'
            val: 'down'
        - df_set_column_val_if:
            column: single_utility_rank_status
            condition: '[single_utility_rank] < [single_utility_rank_before]'
            val: 'up'
        - df_set_column_val_if:
            column: single_utility_rank_status
            condition: '[single_utility_rank] == [single_utility_rank_before]'
            val: 'equal'
        ### 累计人效排名状态
        - add_cols:
            - total_utility_rank_status: '-'
        - df_set_column_val_if:
            column: total_utility_rank_status
            condition: '[total_utility_rank] > [total_utility_rank_before]'
            val: 'down'
        - df_set_column_val_if:
            column: total_utility_rank_status
            condition: '[total_utility_rank] < [total_utility_rank_before]'
            val: 'up'
        - df_set_column_val_if:
            column: total_utility_rank_status
            condition: '[total_utility_rank] == [total_utility_rank_before]'
            val: 'equal'


        ### 日均单环比增长, 日均骑手量环比增长,当日人效环比增长 ,累计人效环比增长
        - df_eval:
            - |
              [avg_daily_order_year_ratio] = ([avg_daily_order] - [avg_daily_order_before]) / [avg_daily_order_before]
              [avg_daily_knight_year_ratio] = ([avg_daily_knight] - [avg_daily_knight_before]) / [avg_daily_knight_before]
              [single_utility_year_ratio] = ([single_utility] - [single_utility_before]) / [single_utility_before]
              [total_utility_year_ratio] = ([total_utility] - [total_utility_before]) / [total_utility_before]
      ### 日均单环比状态
        - add_cols:
            - avg_daily_order_year_ratio_status: '-'
        - df_set_column_val_if:
            column: avg_daily_order_year_ratio_status
            condition: '[avg_daily_order_year_ratio] > 0'
            val: 'up'
        - df_set_column_val_if:
            column: avg_daily_order_year_ratio_status
            condition: '[avg_daily_order_year_ratio] < 0 '
            val: 'down'
        - df_set_column_val_if:
            column: avg_daily_order_year_ratio_status
            condition: '[avg_daily_order_year_ratio] == 0'
            val: 'equal'
      ### 日均骑手量环比状态
        - add_cols:
            - avg_daily_knight_year_ratio_status: '-'
        - df_set_column_val_if:
            column: avg_daily_knight_year_ratio_status
            condition: '[avg_daily_knight_year_ratio] > 0'
            val: 'up'
        - df_set_column_val_if:
            column: avg_daily_knight_year_ratio_status
            condition: '[avg_daily_knight_year_ratio] < 0 '
            val: 'down'
        - df_set_column_val_if:
            column: avg_daily_knight_year_ratio_status
            condition: '[avg_daily_knight_year_ratio] == 0'
            val: 'equal'
      ### 当日人效环比状态
        - add_cols:
            - single_utility_year_ratio_status: '-'
        - df_set_column_val_if:
            column: single_utility_year_ratio_status
            condition: '[single_utility_year_ratio] > 0'
            val: 'up'
        - df_set_column_val_if:
            column: single_utility_year_ratio_status
            condition: '[single_utility_year_ratio] < 0 '
            val: 'down'
        - df_set_column_val_if:
            column: single_utility_year_ratio_status
            condition: '[single_utility_year_ratio] == 0'
            val: 'equal'
      ###累计人效环比状态
        - add_cols:
            - total_utility_year_ratio_status: '-'
        - df_set_column_val_if:
            column: total_utility_year_ratio_status
            condition: '[total_utility_year_ratio] > 0'
            val: 'up'
        - df_set_column_val_if:
            column: total_utility_year_ratio_status
            condition: '[total_utility_year_ratio] < 0 '
            val: 'down'
        - df_set_column_val_if:
            column: total_utility_year_ratio_status
            condition: '[total_utility_year_ratio] == 0'
            val: 'equal'

        - fetch_cols:
            columns: [supplier_id,supplier_name,city_name,meta_day,dimension,total_join_rank_count,dc_count,total_order,single_daily_order,single_daily_order_rank,single_daily_order_rank_status,total_order_rank,total_order_rank_status,avg_daily_order,avg_daily_order_rank,avg_daily_order_rank_status,avg_daily_order_year_ratio,avg_daily_order_year_ratio_status,avg_daily_knight,avg_daily_knight_rank,avg_daily_knight_rank_status,avg_daily_knight_year_ratio,avg_daily_knight_year_ratio_status,single_utility,single_utility_rank,single_utility_rank_status,single_utility_year_ratio,total_utility,total_utility_year_ratio,total_utility_year_ratio_status,total_utility_rank,total_utility_rank_status,single_utility_year_ratio_status,have_order_knight,have_order_ratio,entry_knight,entry_ratio,leave_knight,leave_ratio,star_level,star_level_rank,daily_stay_ratio_rank,daily_stay_ratio,total_leave_ratio,total_entry_ratio,total_order_join_rank_count,single_daily_order_join_rank_count,avg_daily_order_join_rank_count,avg_daily_knight_join_rank_count,single_utility_join_rank_count,total_utility_join_rank_count]
        - set_meta_month_column:
            - book_month

## 总体详情
    - name: mt_total_details
      sync_result: true
      cooks:
        - use_df:
            key: mt_total_details_dc
        - stash_push_df: []

        - use_df:
            key: mt_total_details_city
        - stash_push_df: []

        - stash_concat_df:
            drop_stash: true
        - df_rename_columns:
            - meta_day: book_day
        - df_to_int:
            - book_day

### 历史星级KPI
    - name: mt_star_level_and_kpi_tendency
      sync_result: true
      cooks:
        - fetch_dataset:
            dataset_type_code: mt_total_details
            dataset_cate: std
            month_offset: -1
            ignore_null_error: true
            empty_df_record:
              supplier_name: '-'
              supplier_id: '-'
              city_name: '-'
              vendor_dc_id: '-'
              dc_name: '-'
              book_month: 999999
              book_day: 19790101
              dimension: '-'
              star_level: 0.0
              kpi_score: 0.0
              total_utility: 0.0
              avg_daily_order: 0.0
              star_level_rank: 0
              daily_stay_ratio_rank: 0
              daily_stay_ratio: 0.0
              total_leave_ratio: 0.0
              total_entry_ratio: 0.0
        - run_py:
            - |
              df = df[df['book_day'] == df['book_day'].max()]
              result = df
        - stash_push_df: []
        - fetch_dataset:
            dataset_type_code: mt_total_details
            dataset_cate: std
            month_offset: -2
            ignore_null_error: true
            empty_df_record:
              supplier_name: '-'
              supplier_id: '-'
              city_name: '-'
              vendor_dc_id: '-'
              dc_name: '-'
              book_month: 999999
              book_day: 19790101
              dimension: '-'
              star_level: 0.0
              kpi_score: 0.0
              total_utility: 0.0
              avg_daily_order: 0.0
              star_level_rank: 0
              daily_stay_ratio_rank: 0
              daily_stay_ratio: 0.0
              total_leave_ratio: 0.0
              total_entry_ratio: 0.0
        - run_py:
            - |
              df = df[df['book_day'] == df['book_day'].max()]
              result = df
        - stash_push_df: []
        - fetch_dataset:
            dataset_type_code: mt_total_details
            dataset_cate: std
            month_offset: -3
            ignore_null_error: true
            empty_df_record:
              supplier_name: '-'
              supplier_id: '-'
              city_name: '-'
              vendor_dc_id: '-'
              dc_name: '-'
              book_month: 999999
              book_day: 19790101
              dimension: '-'
              star_level: 0.0
              kpi_score: 0.0
              total_utility: 0.0
              avg_daily_order: 0.0
              star_level_rank: 0
              daily_stay_ratio_rank: 0
              daily_stay_ratio: 0.0
              total_leave_ratio: 0.0
              total_entry_ratio: 0.0
        - run_py:
            - |
              df = df[df['book_day'] == df['book_day'].max()]
              result = df
        - stash_push_df: []
        - fetch_dataset:
            dataset_type_code: mt_total_details
            dataset_cate: std
            month_offset: -4
            ignore_null_error: true
            empty_df_record:
              supplier_name: '-'
              supplier_id: '-'
              city_name: '-'
              vendor_dc_id: '-'
              dc_name: '-'
              book_month: 999999
              book_day: 19790101
              dimension: '-'
              star_level: 0.0
              kpi_score: 0.0
              total_utility: 0.0
              avg_daily_order: 0.0
              star_level_rank: 0
              daily_stay_ratio_rank: 0
              daily_stay_ratio: 0.0
              total_leave_ratio: 0.0
              total_entry_ratio: 0.0
        - run_py:
            - |
              df = df[df['book_day'] == df['book_day'].max()]
              result = df
        - stash_push_df: []
        - fetch_dataset:
            dataset_type_code: mt_total_details
            dataset_cate: std
            month_offset: -5
            ignore_null_error: true
            empty_df_record:
              supplier_name: '-'
              supplier_id: '-'
              city_name: '-'
              vendor_dc_id: '-'
              dc_name: '-'
              book_month: 999999
              book_day: 19790101
              dimension: '-'
              star_level: 0.0
              kpi_score: 0.0
              total_utility: 0.0
              avg_daily_order: 0.0
              star_level_rank: 0
              daily_stay_ratio_rank: 0
              daily_stay_ratio: 0.0
              total_leave_ratio: 0.0
              total_entry_ratio: 0.0
        - run_py:
            - |
              df = df[df['book_day'] == df['book_day'].max()]
              result = df
        - stash_push_df: []
        - fetch_dataset:
            dataset_type_code: mt_total_details
            dataset_cate: std
            month_offset: -6
            ignore_null_error: true
            empty_df_record:
              supplier_name: '-'
              supplier_id: '-'
              city_name: '-'
              vendor_dc_id: '-'
              dc_name: '-'
              book_month: 999999
              book_day: 19790101
              dimension: '-'
              star_level: 0.0
              kpi_score: 0.0
              total_utility: 0.0
              avg_daily_order: 0.0
              star_level_rank: 0
              daily_stay_ratio_rank: 0
              daily_stay_ratio: 0.0
              total_leave_ratio: 0.0
              total_entry_ratio: 0.0
        - run_py:
            - |
              df = df[df['book_day'] == df['book_day'].max()]
              result = df
        - stash_push_df: []
        - fetch_dataset:
            dataset_type_code: mt_total_details
            dataset_cate: std
            month_offset: -7
            ignore_null_error: true
            empty_df_record:
              supplier_name: '-'
              supplier_id: '-'
              city_name: '-'
              vendor_dc_id: '-'
              dc_name: '-'
              book_month: 999999
              book_day: 19790101
              dimension: '-'
              star_level: 0.0
              kpi_score: 0.0
              total_utility: 0.0
              avg_daily_order: 0.0
              star_level_rank: 0
              daily_stay_ratio_rank: 0
              daily_stay_ratio: 0.0
              total_leave_ratio: 0.0
              total_entry_ratio: 0.0
        - run_py:
            - |
              df = df[df['book_day'] == df['book_day'].max()]
              result = df
        - stash_push_df: []
        - fetch_dataset:
            dataset_type_code: mt_total_details
            dataset_cate: std
            month_offset: -8
            ignore_null_error: true
            empty_df_record:
              supplier_name: '-'
              supplier_id: '-'
              city_name: '-'
              vendor_dc_id: '-'
              dc_name: '-'
              book_month: 999999
              book_day: 19790101
              dimension: '-'
              star_level: 0.0
              kpi_score: 0.0
              total_utility: 0.0
              avg_daily_order: 0.0
              star_level_rank: 0
              daily_stay_ratio_rank: 0
              daily_stay_ratio: 0.0
              total_leave_ratio: 0.0
              total_entry_ratio: 0.0
        - run_py:
            - |
              df = df[df['book_day'] == df['book_day'].max()]
              result = df
        - stash_push_df: []
        - fetch_dataset:
            dataset_type_code: mt_total_details
            dataset_cate: std
            month_offset: -9
            ignore_null_error: true
            empty_df_record:
              supplier_name: '-'
              supplier_id: '-'
              city_name: '-'
              vendor_dc_id: '-'
              dc_name: '-'
              book_month: 999999
              book_day: 19790101
              dimension: '-'
              star_level: 0.0
              kpi_score: 0.0
              total_utility: 0.0
              avg_daily_order: 0.0
              star_level_rank: 0
              daily_stay_ratio_rank: 0
              daily_stay_ratio: 0.0
              total_leave_ratio: 0.0
              total_entry_ratio: 0.0
        - run_py:
            - |
              df = df[df['book_day'] == df['book_day'].max()]
              result = df
        - stash_push_df: []
        - fetch_dataset:
            dataset_type_code: mt_total_details
            dataset_cate: std
            month_offset: -10
            ignore_null_error: true
            empty_df_record:
              supplier_name: '-'
              supplier_id: '-'
              city_name: '-'
              vendor_dc_id: '-'
              dc_name: '-'
              book_month: 999999
              book_day: 19790101
              dimension: '-'
              star_level: 0.0
              kpi_score: 0.0
              total_utility: 0.0
              avg_daily_order: 0.0
              star_level_rank: 0
              daily_stay_ratio_rank: 0
              daily_stay_ratio: 0.0
              total_leave_ratio: 0.0
              total_entry_ratio: 0.0
        - run_py:
            - |
              df = df[df['book_day'] == df['book_day'].max()]
              result = df
        - stash_push_df: []
        - fetch_dataset:
            dataset_type_code: mt_total_details
            dataset_cate: std
            month_offset: -11
            ignore_null_error: true
            empty_df_record:
              supplier_name: '-'
              supplier_id: '-'
              city_name: '-'
              vendor_dc_id: '-'
              dc_name: '-'
              book_month: 999999
              book_day: 19790101
              dimension: '-'
              star_level: 0.0
              kpi_score: 0.0
              total_utility: 0.0
              avg_daily_order: 0.0
              star_level_rank: 0
              daily_stay_ratio_rank: 0
              daily_stay_ratio: 0.0
              total_leave_ratio: 0.0
              total_entry_ratio: 0.0
        - run_py:
            - |
              df = df[df['book_day'] == df['book_day'].max()]
              result = df
        - stash_push_df: []
        - fetch_dataset:
            dataset_type_code: mt_total_details
            dataset_cate: std
            month_offset: -12
            ignore_null_error: true
            empty_df_record:
              supplier_name: '-'
              supplier_id: '-'
              city_name: '-'
              vendor_dc_id: '-'
              dc_name: '-'
              book_month: 999999
              book_day: 19790101
              dimension: '-'
              star_level: 0.0
              kpi_score: 0.0
              total_utility: 0.0
              avg_daily_order: 0.0
              star_level_rank: 0
              daily_stay_ratio_rank: 0
              daily_stay_ratio: 0.0
              total_leave_ratio: 0.0
              total_entry_ratio: 0.0
        - stash_push_df: []
        - use_df:
            key: mt_total_details
            columns: [supplier_name,supplier_id,city_name,vendor_dc_id,dc_name,book_month,book_day,dimension,star_level,kpi_score,total_utility,avg_daily_order,star_level_rank,daily_stay_ratio_rank,daily_stay_ratio,total_leave_ratio,total_entry_ratio]
        - run_py:
            - |
              df = to_df(df)
              max_day = df['book_day'].max()
              df = df[df['book_day'] == max_day]
              result = to_dd(df)
        - fetch_cols:
            columns: [supplier_name,supplier_id,city_name,vendor_dc_id,dc_name,book_month,dimension,star_level,kpi_score,total_utility,avg_daily_order,star_level_rank,daily_stay_ratio_rank,daily_stay_ratio,total_leave_ratio,total_entry_ratio]
        - stash_push_df: []
        - stash_concat_df:
            drop_stash: true


### 骑手影响站点分布
    - name: mt_knight_affect_dc_score
      sync_result: true
      cooks:
        - fetch_dataset:
            template_code: mt_day_18      #单日骑手数据
            dataset_cate: raw
            columns: [ 骑手ID,站点ID,站点,完成单量,在岗时长,meta_day]
            ignore_null_error: true
            empty_df_record:
              骑手ID: '-'
              站点ID: '-'
              站点: '-'
              完成单量: 0
              在岗时长: 0.0
              meta_day: '-'
            rename:
              骑手ID: knight_id
              站点ID: vendor_dc_id
              站点: dc_name
              完成单量: single_daily_order
              在岗时长: on_guard_time
        - add_cols:
            - attendance: 0
        - df_set_column_val_if:
            column: attendance
            condition: '[single_daily_order] == 0 '
            val: 0
            else_val: 1
        - run_py:
            - |
              df = to_df(df)
              need = df.groupby(by=['vendor_dc_id','knight_id'])['attendance'].sum().reset_index()
              max_day = df['meta_day'].max()
              df_max_day = df[df['meta_day'] == max_day ][['vendor_dc_id','dc_name','knight_id','single_daily_order','on_guard_time','meta_day']]
              df = pd.merge(df_max_day,need,on=['vendor_dc_id','knight_id'],how='left',sort=False)
              df['days'] = df['meta_day'].map(str).str[6:8].map(int)
              df['attendance_ratio'] = df['attendance'] / df['days']
              result = to_dd(df)
        - add_cols:
            - daily_order_not_standard_count: 0
              on_guard_time_not_standard_count: 0
              attendance_not_standard_count: 0
              get_standard_count: 0
              total_knight: 1
        - df_set_column_val_if:
            column: daily_order_not_standard_count
            condition: '[single_daily_order] < 9 '
            val: 1
            else_val: 0
        - df_set_column_val_if:
            column: on_guard_time_not_standard_count
            condition: '[on_guard_time] <  180 '
            val: 1
            else_val: 0
        - df_set_column_val_if:
            column: attendance_not_standard_count
            condition: '[attendance_ratio] < 0.75 '
            val: 1
            else_val: 0
        - df_set_column_val_if:
            column: get_standard_count
            condition: '([on_guard_time_not_standard_count] != 1) & ([daily_order_not_standard_count] != 1) & ([attendance_not_standard_count] != 1)'
            val: 1
            else_val: 0
        - df_groupby:
            by: [ vendor_dc_id,dc_name,meta_day]
        - df_sum:
            column: [daily_order_not_standard_count,on_guard_time_not_standard_count,attendance_not_standard_count,get_standard_count,total_knight]
        - df_reset_index: []
        - df_eval:
            - |
              [low_standard_count] = [total_knight] - [get_standard_count]
              [get_standard_count_ratio] = [get_standard_count] / [total_knight]
              [low_standard_count_ratio] = 1 - [get_standard_count_ratio]
        - stash_push_df: []

        - fetch_dataset:
            dataset_type_code: std_qplus_dc
            dataset_cate: std
            columns: [ platform_code,supplier_id,supplier_name,city_name,vendor_dc_id ]
            ignore_null_error: true
        - when_empty_fetch_dataset:
            dataset_type_code: std_qplus_dc
            dataset_cate: std
            columns: [ platform_code,supplier_id,supplier_name,city_name,vendor_dc_id ]
            month_offset: -1
            ignore_null_error: true
        - drop_duplicates:
            subset: [ platform_code,supplier_id,vendor_dc_id ]
        - df_select:
            - '[platform_code] == @p1'
            - p1: meituan
        - stash_push_df: [ ]
        - stash_join_df:
            on: [ vendor_dc_id ]
            how: inner
            drop_stash: true
        - add_cols:
            - dimension: 'D'

## 权限——基础数据表
    - name: mt_authority_raw_data
      sync_result: true
      cooks:
        - fetch_dataset:
            template_code: mt_day_35        #单日站点数据
            dataset_cate: raw
            columns: [ 站点id,meta_day,meta_month ]
            ignore_null_error: true
            empty_df_record:
              站点id: '-'
              meta_day: '-'
              meta_month: '-'
            rename:
              站点id: vendor_dc_id
        - drop_duplicates:
            subset: [vendor_dc_id, meta_month]
        - fetch_cols:
            columns: [ vendor_dc_id,meta_month]

    - name: mt_kpi_detail
      sync_result: true
      cooks:
        - fetch_dataset:
            template_code: mt_day_13
            dataset_cate: raw
            datakit_pull_way: last_day
            ignore_null_error: true
            empty_df_record:
              加盟站ID: 0
              加盟站名称: '-'
              完成单(未剔除异常单): 0
              星级: 0
              得分: 0
              提前点送达(复合)订单数: 0
              15分钟超时订单数: 0
              不满意订单数: 0
              配送原因未完成数: 0
              一般超时单量(考核): 0
              严重超时单量(考核): 0
              提前点送达率(复合): 0.0%
              15分钟超时订单占比: 0.0%
              不满意率: 0.0%
              配送原因未完成率: 0.0%
              复合准时率（考核）: 0.0%
              meta_day: 99999999
              meta_month: 999999
            columns:
              - 加盟站ID
              - 加盟站名称
              - 完成单(未剔除异常单)
              - 星级
              - 得分
              - 提前点送达(复合)订单数
              - 15分钟超时订单数
              - 不满意订单数
              - 配送原因未完成数
              - 一般超时单量(考核)
              - 严重超时单量(考核)
              - 提前点送达率(复合)
              - 15分钟超时订单占比
              - 不满意率
              - 配送原因未完成率
              - 复合准时率（考核）
              - meta_day
              - meta_month
            rename:
              加盟站ID: vendor_dc_id
              加盟站名称: dc_name
              完成单(未剔除异常单): total_order
              星级: star_level
              得分: total_score
              提前点送达(复合)订单数: advance_delivery_orders
              15分钟超时订单数: over_15_orders
              不满意订单数: dissatisfy_orders
              配送原因未完成数: unfinished_orders
              一般超时单量(考核): ordinary_over_time_orders
              严重超时单量(考核): serious_over_time_orders
              提前点送达率(复合): advance_delivery_ratio
              15分钟超时订单占比: over_15_ratio
              不满意率: dissatisfy_ratio
              配送原因未完成率: unfinished_ratio
              复合准时率（考核）: punctuality_ratio
              meta_day: book_day
              meta_month: book_month
        - add_cols:
            - advance_delivery_score: 0
        - add_cols:
            - over_15_ratio_score: 0
        - add_cols:
            - dissatisfy_ratio_score: 0
        - add_cols:
            - unfinished_ratio_score: 0
        - add_cols:
            - punctuality_ratio_score: 0
        - add_cols:
            - avg_daily_order: 0
        - add_cols:
            - punctuality_contains: 0
        - add_cols:
            - punctuality_surplus: 0
        - add_cols:
            - advance_delivery_contains: 0
        - add_cols:
            - advance_delivery_surplus: 0
        - add_cols:
            - over_15_contains: 0
        - add_cols:
            - over_15_surplus: 0
        - add_cols:
            - dissatisfy_contains: 0
        - add_cols:
            - dissatisfy_surplus: 0
        - add_cols:
            - unfinished_contains: 0
        - add_cols:
            - unfinished_surplus: 0
        - df_to_float:
            - advance_delivery_score
        - df_to_float:
            - over_15_ratio_score
        - df_to_float:
            - dissatisfy_ratio_score
        - df_to_float:
            - unfinished_ratio_score
        - df_to_float:
            - punctuality_ratio_score
        - df_to_float:
            - avg_daily_order
        - df_to_float:
            - punctuality_contains
        - df_to_float:
            - punctuality_surplus
        - df_to_float:
            - advance_delivery_contains
        - df_to_float:
            - advance_delivery_surplus
        - df_to_float:
            - over_15_contains
        - df_to_float:
            - over_15_surplus
        - df_to_float:
            - dissatisfy_contains
        - df_to_float:
            - dissatisfy_surplus
        - df_to_float:
            - unfinished_contains
        - df_to_float:
            - unfinished_surplus
        - str_strip_column:
            column: advance_delivery_ratio
            char: '%'
        - df_to_float:
            - advance_delivery_ratio
        - df_eval:
            - '[advance_delivery_ratio] = [advance_delivery_ratio] / 100'
        - str_strip_column:
            column: over_15_ratio
            char: '%'
        - df_to_float:
            - over_15_ratio
        - df_eval:
            - '[over_15_ratio] = [over_15_ratio] / 100'
        - str_strip_column:
            column: dissatisfy_ratio
            char: '%'
        - df_to_float:
            - dissatisfy_ratio
        - df_eval:
            - '[dissatisfy_ratio] = [dissatisfy_ratio] / 100'
        - str_strip_column:
            column: unfinished_ratio
            char: '%'
        - df_to_float:
            - unfinished_ratio
        - df_eval:
            - '[unfinished_ratio] = [unfinished_ratio] / 100'
        - str_strip_column:
            column: punctuality_ratio
            char: '%'
        - df_to_float:
            - punctuality_ratio
        - df_eval:
            - '[punctuality_ratio] = [punctuality_ratio] / 100'
        - df_to_int:
            - vendor_dc_id
        - run_py:
            - |
              df=to_df(df)
              df['vendor_dc_id']=[u'%s' % i for i in df[u'vendor_dc_id']]
              result=to_dd(df)
        - stash_push_df: []
        - fetch_dataset:
            template_code: mt_month_60
            dataset_cate: raw
            ignore_null_error: true
            empty_df_record:
              站点ID: '-'
              复合准时率X: 0.0%
              复合准时率Y: 0.0%
              复合准时率Z: 0.0%
              配送原因未完成率X: 0.0%
              配送原因未完成率Y: 0.0%
              配送原因未完成率Z: 0.0%
              不满意率X: 0.0%
              不满意率Y: 0.0%
              不满意率Z: 0.0%
              提前点送达率X: 0.0%
              提前点送达率Y: 0.0%
              提前点送达率Z: 0.0%
              15分钟超时订单占比X: 0.0%
              15分钟超时订单占比Y: 0.0%
              15分钟超时订单占比Z: 0.0%
            columns:
              - 站点ID
              - 复合准时率X
              - 复合准时率Y
              - 复合准时率Z
              - 配送原因未完成率X
              - 配送原因未完成率Y
              - 配送原因未完成率Z
              - 不满意率X
              - 不满意率Y
              - 不满意率Z
              - 提前点送达率X
              - 提前点送达率Y
              - 提前点送达率Z
              - 15分钟超时订单占比X
              - 15分钟超时订单占比Y
              - 15分钟超时订单占比Z
            rename:
              站点ID: vendor_dc_id
              复合准时率X: X1
              复合准时率Y: Y1
              复合准时率Z: Z1
              配送原因未完成率X: X2
              配送原因未完成率Y: Y2
              配送原因未完成率Z: Z2
              不满意率X: X3
              不满意率Y: Y3
              不满意率Z: Z3
              提前点送达率X: X4
              提前点送达率Y: Y4
              提前点送达率Z: Z4
              15分钟超时订单占比X: X5
              15分钟超时订单占比Y: Y5
              15分钟超时订单占比Z: Z5
        - str_strip_column:
            column: X1
            char: '%'
        - df_to_float:
            - X1
        - df_eval:
            - '[X1] = [X1] / 100'
        - str_strip_column:
            column: Y1
            char: '%'
        - df_to_float:
            - Y1
        - df_eval:
            - '[Y1] = [Y1] / 100'
        - str_strip_column:
            column: Z1
            char: '%'
        - df_to_float:
            - Z1
        - df_eval:
            - '[Z1] = [Z1] / 100'
        - str_strip_column:
            column: X2
            char: '%'
        - df_to_float:
            - X2
        - df_eval:
            - '[X2] = [X2] / 100'
        - str_strip_column:
            column: Y2
            char: '%'
        - df_to_float:
            - Y2
        - df_eval:
            - '[Y2] = [Y2] / 100'
        - str_strip_column:
            column: Z2
            char: '%'
        - df_to_float:
            - Z2
        - df_eval:
            - '[Z2] = [Z2] / 100'
        - str_strip_column:
            column: X3
            char: '%'
        - df_to_float:
            - X3
        - df_eval:
            - '[X3] = [X3] / 100'
        - str_strip_column:
            column: Y3
            char: '%'
        - df_to_float:
            - Y3
        - df_eval:
            - '[Y3] = [Y3] / 100'
        - str_strip_column:
            column: Z3
            char: '%'
        - df_to_float:
            - Z3
        - df_eval:
            - '[Z3] = [Z3] / 100'
        - str_strip_column:
            column: X4
            char: '%'
        - df_to_float:
            - X4
        - df_eval:
            - '[X4] = [X4] / 100'
        - str_strip_column:
            column: Y4
            char: '%'
        - df_to_float:
            - Y4
        - df_eval:
            - '[Y4] = [Y4] / 100'
        - str_strip_column:
            column: Z4
            char: '%'
        - df_to_float:
            - Z4
        - df_eval:
            - '[Z4] = [Z4] / 100'
        - str_strip_column:
            column: X5
            char: '%'
        - df_to_float:
            - X5
        - df_eval:
            - '[X5] = [X5] / 100'
        - str_strip_column:
            column: Y5
            char: '%'
        - df_to_float:
            - Y5
        - df_eval:
            - '[Y5] = [Y5] / 100'
        - str_strip_column:
            column: Z5
            char: '%'
        - df_to_float:
            - Z5
        - df_eval:
            - '[Z5] = [Z5] / 100'
        - df_to_int:
            - vendor_dc_id
        - run_py:
            - |
              df=to_df(df)
              df['vendor_dc_id']=[u'%s' % i for i in df[u'vendor_dc_id']]
              result=to_dd(df)
        - stash_push_df: []
        - stash_join_df:
            how: right
            on: vendor_dc_id
            fillna: 0
            drop_stash: True
        - set_meta_days_column:
            - 当月总天数
        - run_py:
            - |
              df=to_df(df)
              df['days'] = df['book_day'].map(str).str[6:8].map(int)
              result = to_dd(df)
        - push_dataset:
            key: mt_kpi_detail_mini

###提前点送达得分
        - use_df:
            key: mt_kpi_detail_mini
        - df_select:
            - '[advance_delivery_ratio] > [X4]'
        - df_eval:
            - '[advance_delivery_score] = 0'
        - stash_push_df: []
        - use_df:
            key: mt_kpi_detail_mini
        - df_select:
            - '[advance_delivery_ratio] <= [X4] & [advance_delivery_ratio] > [Y4]'
        - df_eval:
            - '[advance_delivery_score] = 100* ([advance_delivery_ratio]-[X4])/([Y4]-[X4])'
        - stash_push_df: []
        - use_df:
            key: mt_kpi_detail_mini
        - df_select:
            - '[advance_delivery_ratio] <= [Y4] & [advance_delivery_ratio] > [Z4]'
        - df_eval:
            - '[advance_delivery_score] = 100+20* ([advance_delivery_ratio]-[Y4])/([Z4]-[Y4])'
        - stash_push_df: []
        - use_df:
            key: mt_kpi_detail_mini
        - df_select:
            - '[advance_delivery_ratio] <= [Z4]'
        - df_eval:
            - '[advance_delivery_score] = 120'
        - stash_push_df: []
        - stash_concat_df:
            drop_stash: True
        - push_dataset:
            key: mt_kpi_detail_mini

###15分钟超时占比得分
        - use_df:
            key: mt_kpi_detail_mini
        - df_select:
            - '[over_15_ratio] > [X5]'
        - df_eval:
            - '[over_15_ratio_score] = 0'
        - stash_push_df: []
        - use_df:
            key: mt_kpi_detail_mini
        - df_select:
            - '[over_15_ratio] <= [X5] & [over_15_ratio] > [Y5]'
        - df_eval:
            - '[over_15_ratio_score] = 100* ([over_15_ratio]-[X5])/([Y5]-[X5])'
        - stash_push_df: []
        - use_df:
            key: mt_kpi_detail_mini
        - df_select:
            - '[over_15_ratio] <= [Y5] & [over_15_ratio] > [Z5]'
        - df_eval:
            - '[over_15_ratio_score] = 100+20* ([over_15_ratio]-[Y5])/([Z5]-[Y5])'
        - stash_push_df: []
        - use_df:
            key: mt_kpi_detail_mini
        - df_select:
            - '[over_15_ratio] <= [Z5]'
        - df_eval:
            - '[over_15_ratio_score] = 120'
        - stash_push_df: []
        - stash_concat_df:
            drop_stash: True
        - push_dataset:
            key: mt_kpi_detail_mini

###不满意率得分
        - use_df:
            key: mt_kpi_detail_mini
        - df_select:
            - '[dissatisfy_ratio] > [X3]'
        - df_eval:
            - '[dissatisfy_ratio_score] = 0'
        - stash_push_df: []
        - use_df:
            key: mt_kpi_detail_mini
        - df_select:
            - '[dissatisfy_ratio] <= [X3] & [dissatisfy_ratio] > [Y3]'
        - df_eval:
            - '[dissatisfy_ratio_score] = 100* ([dissatisfy_ratio]-[X3])/([Y3]-[X3])'
        - stash_push_df: []
        - use_df:
            key: mt_kpi_detail_mini
        - df_select:
            - '[dissatisfy_ratio] <= [Y3] & [dissatisfy_ratio] > [Z3]'
        - df_eval:
            - '[dissatisfy_ratio_score] = 100+20* ([dissatisfy_ratio]-[Y3])/([Z3]-[Y3])'
        - stash_push_df: []
        - use_df:
            key: mt_kpi_detail_mini
        - df_select:
            - '[dissatisfy_ratio] <= [Z3]'
        - df_eval:
            - '[dissatisfy_ratio_score] = 120'
        - stash_push_df: []
        - stash_concat_df:
            drop_stash: True
        - push_dataset:
            key: mt_kpi_detail_mini

###配送原因未完成率得分
        - use_df:
            key: mt_kpi_detail_mini
        - df_select:
            - '[unfinished_ratio] > [X2]'
        - df_eval:
            - '[unfinished_ratio_score] = 0'
        - stash_push_df: []
        - use_df:
            key: mt_kpi_detail_mini
        - df_select:
            - '[unfinished_ratio] <= [X2] & [unfinished_ratio] > [Y2]'
        - df_eval:
            - '[unfinished_ratio_score] = 100* ([unfinished_ratio]-[X2])/([Y2]-[X2])'
        - stash_push_df: []
        - use_df:
            key: mt_kpi_detail_mini
        - df_select:
            - '[unfinished_ratio] <= [Y2] & [unfinished_ratio] > [Z2]'
        - df_eval:
            - '[unfinished_ratio_score] = 100+20* ([unfinished_ratio]-[Y2])/([Z2]-[Y2])'
        - stash_push_df: []
        - use_df:
            key: mt_kpi_detail_mini
        - df_select:
            - '[unfinished_ratio] <= [Z2]'
        - df_eval:
            - '[unfinished_ratio_score] = 120'
        - stash_push_df: []
        - stash_concat_df:
            drop_stash: True
        - push_dataset:
            key: mt_kpi_detail_mini

###复合准时率得分
        - use_df:
            key: mt_kpi_detail_mini
        - df_select:
            - '[punctuality_ratio] < [X1]'
        - df_eval:
            - '[punctuality_ratio_score] = 0'
        - stash_push_df: []
        - use_df:
            key: mt_kpi_detail_mini
        - df_select:
            - '[punctuality_ratio] >= [X1] & [punctuality_ratio] < [Y1]'
        - df_eval:
            - '[punctuality_ratio_score] = 100* ([punctuality_ratio]-[X1])/([Y1]-[X1])'
        - stash_push_df: []
        - use_df:
            key: mt_kpi_detail_mini
        - df_select:
            - '[punctuality_ratio] >= [Y1] & [punctuality_ratio] < [Z1]'
        - df_eval:
            - '[punctuality_ratio_score] = 100+20* ([punctuality_ratio]-[Y1])/([Z1]-[Y1])'
        - stash_push_df: []
        - use_df:
            key: mt_kpi_detail_mini
        - df_select:
            - '[punctuality_ratio] >= [Z1]'
        - df_eval:
            - '[punctuality_ratio_score] = 120'
        - stash_push_df: []
        - stash_concat_df:
            drop_stash: True
###日均单
        - df_eval:
            - '[avg_daily_order] = [total_order]/[days]'

###复合配送准时（容错值）& 复合配送准时（余量）
        - df_to_int:
            - ordinary_over_time_orders
        - df_to_int:
            - serious_over_time_orders
        - df_eval:
            - '[punctuality_contains] = [avg_daily_order]*[当月总天数]*(1 - [Z1])'
        - df_eval:
            - '[punctuality_surplus] = [punctuality_contains] - 1*[ordinary_over_time_orders] - 5*[serious_over_time_orders]'

###提前点送达单量（容错值）& 提前点送达单量（余量）
        - df_to_int:
            - advance_delivery_orders
        - df_eval:
            - '[advance_delivery_contains] = [avg_daily_order]*[当月总天数]*[Z4]'
        - df_eval:
            - '[advance_delivery_surplus] = [advance_delivery_contains] - [advance_delivery_orders]'

###15分钟超时单量（容错值）& 15分钟超时单量（余量）
        - df_to_int:
            - over_15_orders
        - df_eval:
            - '[over_15_contains] = [avg_daily_order]*[当月总天数]*[Z5]'
        - df_eval:
            - '[over_15_surplus] = [over_15_contains] - [over_15_orders]'
###不满意单量（容错值）& 不满意单量（余量）
        - df_to_int:
            - dissatisfy_orders
        - df_eval:
            - '[dissatisfy_contains] = [avg_daily_order]*[当月总天数]*[Z3]'
        - df_eval:
            - '[dissatisfy_surplus] = [dissatisfy_contains] - [dissatisfy_orders]'

###配送原因未完成单量（容错值）& 配送原因未完成单量（余量）
        - df_to_int:
            - unfinished_orders
        - df_eval:
            - '[unfinished_contains] = [avg_daily_order]*[当月总天数]*[Z2]'
        - df_eval:
            - '[unfinished_surplus] = [unfinished_contains] - [unfinished_orders]'
        - stash_push_df: []
        - fetch_dataset:
            dataset_type_code: std_qplus_dc
            dataset_cate: std
            ignore_null_error: true
            columns:
              - supplier_id
              - vendor_dc_id
              - city_name
              - supplier_name
        - when_empty_fetch_dataset:
            dataset_type_code: std_qplus_dc
            dataset_cate: std
            month_offset: -1
            ignore_null_error: true
            columns:
              - supplier_id
              - vendor_dc_id
              - city_name
              - supplier_name
        - drop_duplicates:
            subset: [ supplier_id,vendor_dc_id ,city_name ]
        - stash_push_df: []
        - stash_join_df:
            on: [ vendor_dc_id ]
            how: right
            drop_stash: true
### score
    - name: mt_kpi_detail_score
      sync_result: true
      cooks:
        - use_df:
            key: mt_kpi_detail
            columns:
              - supplier_name
              - supplier_id
              - city_name
              - dc_name
              - vendor_dc_id
              - book_month
              - book_day
              - star_level
              - total_score
              - advance_delivery_score
              - over_15_ratio_score
              - dissatisfy_ratio_score
              - unfinished_ratio_score
              - punctuality_ratio_score
            rename:
              star_level: 星级结果
              total_score: 总分
              advance_delivery_score: 提前点送达得分
              over_15_ratio_score: 15分钟超时占比得分
              dissatisfy_ratio_score: 不满意率得分
              unfinished_ratio_score: 配送原因未完成率得分
              punctuality_ratio_score: 复核准时率得分

### orders
    - name: mt_kpi_detail_orders
      sync_result: true
      cooks:
        - use_df:
            key: mt_kpi_detail
            columns:
              - supplier_name
              - supplier_id
              - city_name
              - dc_name
              - vendor_dc_id
              - book_month
              - book_day
              - advance_delivery_orders
              - over_15_orders
              - dissatisfy_orders
              - unfinished_orders
              - ordinary_over_time_orders
              - serious_over_time_orders
            rename:
              advance_delivery_orders: 提前点送达单量
              over_15_orders: 15分钟超时单量
              dissatisfy_orders: 不满意单量
              unfinished_orders: 配送原因未完成单量
              ordinary_over_time_orders: 一般超时单量
              serious_over_time_orders: 严重超时单量

### ratio
    - name: mt_kpi_detail_ratio
      sync_result: true
      cooks:
        - use_df:
            key: mt_kpi_detail
            columns:
              - supplier_name
              - supplier_id
              - city_name
              - dc_name
              - vendor_dc_id
              - book_month
              - book_day
              - advance_delivery_ratio
              - over_15_ratio
              - dissatisfy_ratio
              - unfinished_ratio
              - punctuality_ratio
            rename:
              advance_delivery_ratio: 提前点送达率
              over_15_ratio: 15分钟超时率
              dissatisfy_ratio: 不满意率
              unfinished_ratio: 配送原因未完成率
              punctuality_ratio: 复核准时率

### contains
    - name: mt_kpi_detail_contains
      sync_result: true
      cooks:
        - use_df:
            key: mt_kpi_detail
            columns:
              - supplier_name
              - supplier_id
              - city_name
              - dc_name
              - vendor_dc_id
              - book_month
              - book_day
              - punctuality_contains
              - punctuality_surplus
              - advance_delivery_contains
              - advance_delivery_surplus
              - over_15_contains
              - over_15_surplus
              - dissatisfy_contains
              - dissatisfy_surplus
              - unfinished_contains
              - unfinished_surplus

            rename:
              punctuality_contains: 复核配送准时（容错值）
              punctuality_surplus: 复核配送准时（余量）
              advance_delivery_contains: 提前点送达单量（容错值）
              advance_delivery_surplus: 提前点送达单量（余量）
              over_15_contains: 15分钟超时单量（容错值）
              over_15_surplus: 15分钟超时单量（余量）
              dissatisfy_contains: 不满意单量（容错值）
              dissatisfy_surplus: 不满意单量（余量）
              unfinished_contains: 配送原因未完成单量（容错值）
              unfinished_surplus: 配送原因未完成单量（余量）


    - name: mt_knight_detail
      sync_result: true
      cooks:
        - fetch_dataset:
            template_code: mt_day_18
            dataset_cate: raw
            ignore_null_error: true
            empty_df_record:
              骑手ID: '-'
              骑手: '-'
              站点ID: '-'
              站点: '-'
              骑手接单量: 0
              完成单量: 0
              在岗时长: 0
              meta_day: 0
              meta_month: 0
            columns:
              - 骑手ID
              - 骑手
              - 站点ID
              - 站点
              - 骑手接单量
              - 完成单量
              - 在岗时长
              - meta_day
              - meta_month
            rename:
              骑手ID: knight_id
              骑手: knight_name
              站点ID: vendor_dc_id
              站点: dc_name
              完成单量: avg_daily_order
              在岗时长: on_guard_time
              meta_day: book_day
              meta_month: book_month
        - add_cols:
            - attendance: 0 #出勤率
        - add_cols:
            - avg_daily_order_std_line: 9
        - add_cols:
            - on_guard_time_std_line: 180
        - add_cols:
            - attendance_std_line: 0.75
        - run_py:
            - |
              df=to_df(df)
              df['max_days']=df['book_day'].max()
              df['days'] = df['max_days'].map(str).str[6:8].map(int)
              result = to_dd(df)
        - push_dataset:
            key: mt_day_18_knight_detail
        - use_df:
            key: mt_day_18_knight_detail
        - stash_push_df: []
        - fetch_dataset:
            dataset_type_code: std_qplus_dc
            dataset_cate: std
            ignore_null_error: true
            columns:
              - supplier_id
              - vendor_dc_id
              - city_name
              - supplier_name
        - when_empty_fetch_dataset:
            dataset_type_code: std_qplus_dc
            dataset_cate: std
            month_offset: -1
            ignore_null_error: true
            columns:
              - supplier_id
              - vendor_dc_id
              - city_name
              - supplier_name
        - drop_duplicates:
            subset: [ supplier_id,vendor_dc_id ,city_name ]
        - stash_push_df: []
        - stash_join_df:
            on: [ vendor_dc_id ]
            how: right
            drop_stash: true
        - stash_push_df: []

###骑手出勤率
        - use_df:
            key: mt_day_18_knight_detail
        - add_cols:
            - 出勤天数: 1
        - df_select:
            - '[avg_daily_order] > 0'
        - df_groupby:
            by: [vendor_dc_id,knight_id]
        - df_sum:
            column: [出勤天数]
        - df_reset_index: []
        - stash_push_df: []
        - stash_join_df:
            on: [vendor_dc_id,knight_id]
            how: right
            drop_stash: true
        - df_eval:
            - '[attendance] = [出勤天数] / [days]'
        - run_py:
            - |
              df = to_df(df)
              df=df[df['book_day']==df['book_day'].max()]
              result = to_dd(df)
